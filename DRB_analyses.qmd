---
title: "Inferring the MOA of new drugs through the analysis of heterogeneous response to treatment of different subpopulations of cancer cells"
author: "Bastien CHASSAGNOL and Vera PANCALDI and Luca GRUMULATO"
date: last-modified	
number-sections: true
toc: true
toc-depth: 3
lang: en-GB
# subject: "Cell-cell benchmark"
# keywords: ["cell-cell communication", "benchmark", "spatial transcriptomics", "single-cell"]
# bibliographic options
bibliography: DRB_fingerprints.bib
link-citations: true
highlight-style: github
filters:
  - highlight-text
# code options
execute:
  message: false
  warning: false
  error: false
# Table options
tbl-cap-location: bottom
format: 
  html:
    embed-resources: true
    theme:
      light: cosmo
      dark: cosmo
    sidebar: true
    lightbox: true # Allows to zoom out on figures.
    toc-expand: 2 # by default, level 2 is visible before scrolling
    comments: 
      hypothesis: true
    # code options
    code-fold: show
    code-link: true
    page-layout: full
    collapse: true
  # pdf:
  #   colourlinks: true
  #   cite-method: biblatex
  # docx:
  #   toc-title: Contents
editor: source
---

# Introduction: Cell lines DNA Barcoding

- DNA barcoding is also used for inferring the species abundancies in environement samples, just replace the notion of species by cell lines. Similar statistical issues, with *zero-inflated* distributions.

- Steps: 
  1. Transfection by virus.
  2. Clonal amplification, unique tagging per cell using MOI.
  3. Clone sizes are assumed to be proportional to the barcode abundances due to this 1-1 mapping of a barcode and a single cell.

- Pros DNA barcoding:
  - Better capture of cell population sizes
  - Better tracking of tagged clones.

- Cons DNA barcoding:
  - Lack of systematic reviews and benchmarks.
  - Mostly rely on bulk RNASeq analytical tools, not accounting for *drop-outs*. In particular, the assumptions that variance across tags is homogeneous, and abundancies follow a negative binomial distribution are quite controversial.
  

# Reproduce the analyses: setup configuration

I list below the R packages required to reproduce the analyses.

```{r}
#| label: setup

# data wrangling
library(dplyr)
library(tidyr)
library(stringr)
library(readr)
library(readxl)
library(purrr)

# reporting
library(flextable)
library(testthat)

# plotting
library(ggplot2)
library(ComplexHeatmap)
library(cowplot)
library(grid)

# auxiliary functions
source("R/utils.R")
```

# Data management

-   [Original Google Drive repository](https://drive.google.com/drive/folders/1pMSX4M4kHcDGxcsCzsMYHHM6VRvBHHUO).

    
```{r}
#| label: format-barcode-csv
#| echo: false
#| eval: false
barcode_files <- list.files("./data/barcode-counts/", 
                               pattern = "exp.*\\.xlsx", 
                               full.names = TRUE)

# change format + barcode name
barcode_matrices <- lapply(barcode_files, function(old_filename) {
  expression_matrix <- readxl::read_excel(old_filename) |> 
    rename(barcode_id = 1)
  
  new_filename <- old_filename |> basename() |> tools::file_path_sans_ext()
  
  readr::write_csv(expression_matrix, 
                   file = file.path("data", "barcode-counts", paste0(new_filename, ".csv")))
  
})
```

    
## Experiment selection and formatting {#sec-select-exp}

We early discarded the following expression files:

- ['Experiment Date': `130921` and 'Run Date': `101121` `exp130921_in vivo.csv`]{fg="red"}
- [*In vivo* experience: `exp200921.csv`, 'Experiment Date': `200921` and 'Run Date': `111021`.]{fg="red"}
- [Latest experience `exp281022.csv`, run in parallel to Time Course: 'Experiment Date': `281022` and 'Run Date': `141222`, based on Luca's recommendations.]{fg="red"}


```{r}
#| label: select-expression-1
#| eval: false
#| echo: true

exp130921_expression <- readr::read_csv("data/barcode-counts/exp130921.csv") 
exp130921_1_expression <- readr::read_csv("data/barcode-counts/exp130921_1.csv") 
selected_dataset <- compare_dataframes(exp130921_expression, exp130921_1_expression)
```

[Conclusion: Keep `exp130921.csv`, and discard expression file `exp130921_1.csv`. The latter indeed exhibited fewer barcode IDs, while on the shared overlap, both datasets are identical.]{fg="red"}


```{r}
#| label: rename-erroneous-date
#| eval: false
#| echo: true
#| lst-label: lst-rename-bad-date
#| lst-cap: Update labelling of latest experience.

file.rename("data/barcode-counts/exp211221.csv", "data/barcode-counts/exp271221.csv") 
```

[In @lst-rename-bad-date, we rename expression file `exp211221.csv` into `exp271221.csv`, relying on date annotations.]{fg="red"}


```{r}
#| label: select-expression-dose-response
#| eval: true

exp200921_expression <- readr::read_csv("data/barcode-counts/temp discarded/exp200921.csv") 
exp200921_dose_response <- readr::read_csv("data/barcode-counts/exp200921_dose response osim.csv")
selected_dataset <- compare_dataframes(exp200921_expression, exp200921_dose_response)
```

[While the *dose-response* experience `exp200921_dose response osim` exhibits distinct biological objective, it turned out that the 4 control biological replicates are shared with classical drug response comparison `exp200921.csv`. However, **the number of sequenced barcode IDs differ in both experiences!!** In addition, note that `exp200921.csv` has been tagged as discarded, except for the Controls!!]{fg="red"}
  
  
Code snippets in @lst-281022 and @lst-281022-time-course aim at replacing unprecise labelling of barcode IDs (no concentration, no time duration, ...) in the 2022 batch experiences.

```{r}
#| label: select-expression-281022
#| eval: false
#| echo: true
#| lst-label: lst-281022
#| lst-cap: Update labelling of latest experience.

# extract old colnames
exp281022_expression <- readr::read_csv("data/barcode-counts/exp281022.csv") 
# cat(colnames(exp281022_expression), file = "281022_old_labels.txt", sep = "\n")

# extract mapping old_names with new_names
mapping_old_new_281022 <- readxl::read_excel("data/Table of compounds.xlsx", 
                                             sheet = "Sample Mapping 281022")

labels_old_new_281022 <- setNames(object = mapping_old_new_281022$OLD_replicate_label, 
                                  nm = mapping_old_new_281022$NEW_replicate_label)

# apply change labelling
exp281022_expression <- exp281022_expression |> 
  dplyr::rename(dplyr::all_of(labels_old_new_281022))

readr::write_csv(exp281022_expression, "data/barcode-counts/exp281022.csv")
```


```{r}
#| label: select-expression-281022-time-course
#| eval: false
#| echo: true
#| lst-label: lst-281022-time-course
#| lst-cap: Update time course experiences.

exp281022_expression_timecourse <- readr::read_csv("data/barcode-counts/exp281022_time course.csv") 
# cat(colnames(exp281022_expression_timecourse), file = "281022_timecourse_old_labels.txt", sep = "\n")

# update colnames ----

mapping_old_new_time_course <- read_excel("data/Table of compounds.xlsx", 
                                     sheet = "Sample Mapping Time Course")

labels_old_new_time_course <- setNames(object = mapping_old_new_time_course$OLD_replicate_label, 
                                       nm = mapping_old_new_time_course$NEW_replicate_label)

# apply change labelling
exp281022_expression_timecourse <- exp281022_expression_timecourse |> 
  dplyr::rename(dplyr::all_of(labels_old_new_time_course))

readr::write_csv(exp281022_expression_timecourse,
                 "data/barcode-counts/exp281022_time course.csv")

# To evaluate whether controls are different between experiment 281022 and 281022 Time Course
controls_exp281022 <- exp281022_expression |> 
  select(key_barcode, dplyr::matches("^ctl")) |> 
  dplyr::inner_join(exp281022_expression_timecourse |> 
                      select(key_barcode, dplyr::matches("^Ctrl")),
                    by="key_barcode")
cor(controls_exp281022$ctl2, controls_exp281022$Ctrl2) # they strongly correlate with each other, but not a perfect match -> controls are indeed distinct

exp300821 <- readr::read_csv2("data/barcode-counts/exp300821.csv") |> 
  rename(barcode_id="...1")
readr::write_csv(exp300821, "data/barcode-counts/exp300821.csv")

```

<!-- ### Additional comments -->

<!-- - `exp130921_in_vivo`: cells injected in living mice (control versus osermintinimb). -->
<!-- - `exp281022`: control, protac, cetuximab and gefitinib ($n=4$ replicates each time) were sampled in T25 flasks. P42 and P43 correspond to cells grown without treatment for 42 or 43 passages, and were used for evaluating *barcode drift* technical artefact. -->
<!-- - `exp281022_time course`: time course experiment. -->

### TODO and TOKEEPINMIND: barcode counts

Things to consider:

- [Format used is **French csv**, instead of international CSV. CSV means for 'comma-separated value', maybe consider switching [Excel settings](https://support.microsoft.com/en-us/office/import-or-export-text-txt-or-csv-files-5250ac4c-663c-47ce-937b-339e391393ba).]{fg="red"}
- [I rename the first colname of each expression file as `barcode_id`, storing unequivocal tag.]{fg="red"}
- [Some barcode counts exhibit final line `index`, for which reason?]{fg="red"}
<!-- - Some barcode counts matrices, such as `exp220322.csv` and `exp070222.csv` showcase a final line paired with `index` value, or even a full empty line, such as in `exp200921.csv`. Not really an issue after merging all barcode files. -->

### Overview of barcode samples


```{r}
#| label: tbl-overview-barcode-samples
#| tbl-cap: "Overview of the Barcoding Batches."
#| cache: true
#| tbl-subcap:
#|   - "Kept Batches"
#|   - "Removed batches"
#| layout-ncol: 2

# 1) summarise kept batches ----
barcode_files <- list.files("./data/barcode-counts/",
                            pattern = "exp.*\\.csv",
                            full.names = TRUE)
barcode_summaries <- purrr::map(barcode_files, function(filename) {
  barcode_counts <- readr::read_csv(filename, show_col_types = FALSE)
  experience_name <- filename |> basename() |> tools::file_path_sans_ext()
  experience_summary <- tibble::tibble(`Experience Name`= experience_name,
                                       Features= paste0("Barcode matrix contains: ",
                                                        nrow(barcode_counts),
                                                        " unique barcode IDs, and ",
                                                        ncol(barcode_counts)-1, " replicates."))
  return(experience_summary)
}) |>
  purrr::list_rbind()
flextable::flextable(barcode_summaries) |> 
  bold(part="header")

openxlsx::write.xlsx(barcode_summaries, 
                     file = "./data/kept_experiences_overview.xlsx")

# 2) summarise discarded batches ----

discarded_files <- list.files("./data/barcode-counts/temp discarded/",
                            pattern = "exp.*\\.csv",
                            full.names = TRUE)

# change format + barcode name
barcode_discarded_summaries <- purrr::map(discarded_files, function(filename) {
  barcode_counts <- readr::read_csv(filename, show_col_types = FALSE)
  experience_name <- filename |> basename() |> tools::file_path_sans_ext()
  experience_summary <- tibble::tibble(`Experience Name`= experience_name,
                                       Features= paste0("Barcode matrix contains: ",
                                                        nrow(barcode_counts),
                                                        " unique barcode IDs, and ",
                                                        ncol(barcode_counts)-1, " replicates."))
  return(experience_summary)
}) |>
  purrr::list_rbind()

openxlsx::write.xlsx(barcode_discarded_summaries, 
                     file = "./data/discarded_experiences_overview.xlsx")

flextable::flextable(barcode_discarded_summaries) |> 
  bold(part="header")
```
In @tbl-overview-barcode-samples, we list the final selection of `{r} ncol(barcode_summaries)` barcode experiences considered so far in the analysis, while `{r} ncol(discarded_files)` were not considered for inclusion at all.


## Phenotypes {#sec-metadata-phenotypes}

- [General question: what's the difference between `Run Date` and `Experiment Date`?]{fg="red"}

Most of the R instructions reported in this section aim at rendering the `Table of compounds` file compliant with the `tidy` format, see @tip-tidyformat. These data-wrangling operations are split in 4 steps:

1. In @lst-process-pheno1, we remove columns that are not useful for pairing counts and phenotype information, nor for the statistical design, correct for wrongly reported concentrations, and deal with merged Excel cells that generate spurious missing values.

2. In @lst-process-pheno2, we retrieve from each individual barcode counts profile, the individual replicates ID identifying unequivocally each replicate. We set apart replicates that could be mapped back to original `Table of compounds` file.

3. In @lst-process-pheno3, we merge together in a comprehensive phenotype table the short `Samples_ID` (short term referring to drugs listed in `Samples` column), the full `Samples` (complete name of drugs) and map each of them to its complete list of replicates (from 2 to 8). We save the output in `data-derived`.

4. Finally, in @lst-check-pheno-data-1 and @lst-check-pheno-data-2, we perform several posterior *data integrity checks* to verify if i) we were able to map each individual replicate ID to its original ID in `Table of compounds`, and ii) if the number of replicates reported in [`Table of compounds`](data/Table of compounds.xlsx) was consistent with the number of barcode profiles.

```{r}
#| label: process-pheno1
#| lst-label: lst-process-pheno1
#| lst-cap: Coerce original Excel file reporting experimental design to tidy format.

pheno_colnames <- c(Level1 = "Pathways", Level2 = "...2", 
                    Samples = "Samples", Replicates = "Replicates",
                    Concentrations = "Concentrations", Date = "Experiment date",
                    `Run date` = "Run date", Duration="Duration", 
                    Kept="Kept", Comments = "Comments")

# prune irrelevant colnames ----
pheno_data <- readxl::read_xlsx("data/Table of compounds.xlsx",
                                sheet = "Experimental Design",
                                col_types = c(rep("text", 3), "numeric", 
                                              rep("text", 4), "logical", "text")) |>
  rename(all_of(pheno_colnames)) |>
  # tidyr::drop_na(Replicates, Date) |> # 3 cells seem erroenously merged
  # missing_rows <- which(is.na(pheno_data$Replicates) & is.na(pheno_data$Date))
  tidyr::fill(Level1, Level2, .direction = "down")

# correct Table of compounds' content (wrongly reported Dates or concentrations) ----

pheno_data <- pheno_data |> 
  # extract last 6 numbers, as the only ones used for identification of samples downstream
  dplyr::mutate(Samples = if_else(grepl("Control", Level2, ignore.case = TRUE),
                                  Level2, Samples),
                `Run date` = stringr::str_sub(`Run date`, -6, -1),
                Batch_ID= paste0("exp", Date)) |> 
  # Date = if_else(Samples %in% "SBI-0206965", "181021", Date),
  # `Run date` = if_else(Samples %in% "SBI-0206965", "251121", `Run date`)) |>
  tidyr::fill(Samples, .direction = "down") |>
  # remove unwanted replicates
  dplyr::filter(Kept) |> 
  dplyr::mutate(Batch_ID = dplyr::if_else(Date=="200921" & 
                                            `Run date` =="101121" & 
                                            Samples == "Osimertinb", 
                                          "exp200921_dose response osim", Batch_ID)) |> 
  dplyr::mutate(Batch_ID = dplyr::if_else(Date=="200921" & 
                                            `Run date` =="111021" & 
                                            Samples == "Control", 
                                          "exp200921_dose response osim", Batch_ID)) |> 
  dplyr::mutate(Batch_ID = dplyr::if_else(Comments %in% c("Time Course"), 
                                          "exp281022_time course", Batch_ID)) |> 
  dplyr::select(- Comments, -Kept) |> 
  # remove duplicates
  dplyr::distinct(.keep_all = TRUE)

# format concentrations, creating both 'Concentrations_ID' and 'Concentrations' in Moles ----
pheno_data <- pheno_data |> 
  dplyr::mutate(Concentrations=if_else(Samples=="Control", "000 uM", Concentrations)) |> 
  # dplyr::mutate(Concentrations=if_else(Samples=="Osimertinb+sorafenib", "015 uM", Concentrations)) |> 
  tidyr::separate_wider_delim(Concentrations, delim = " ", names = c("Concentrations Value", "Unit"), cols_remove = FALSE) |> 
  dplyr::rename(OLD_Concentrations=Concentrations) |> 
  dplyr::mutate(Unit = case_when(
    Unit %in% c("uM", "µM", "µg/ml") ~ "u",
    Unit == "nM" ~ "n", 
    Unit %in% c("mg/kg", "mM") ~ "m", 
  )) |> 
  dplyr::mutate(Concentrations=parse_number(`Concentrations Value`, trim_ws = TRUE, 
                                            locale = locale(decimal_mark = ",", grouping_mark = "."))) |> 
   dplyr::mutate(Concentrations = case_when(
    Unit == "u" ~ Concentrations *10^-6,
    Unit == "n" ~ Concentrations *10^-9, 
    Unit == "m" ~ Concentrations *10^-3)) |> 
  dplyr::mutate(`Concentrations Value`=parse_number(`Concentrations Value`, trim_ws = TRUE, 
                                            locale = locale(decimal_mark = ",", grouping_mark = ".")) |> 
                  format_concentrations()) |> 
  tidyr::unite(col ="Concentrations_ID", `Concentrations Value`, Unit, sep = "")

# format Durations, creating both 'Duration_ID' and 'Duration' as an integer value in Days ----
pheno_data <- pheno_data |> 
  # extract last 6 numbers, as the only ones used for identification of samples downstream
  dplyr::mutate(Duration_ID = Duration,
                Duration = parse_number(Duration, trim_ws = TRUE, 
                                        locale = locale(decimal_mark = ".")), 
                Duration = dplyr::if_else(grepl("m$",  Duration_ID),
                                          Duration*30, Duration)) 
  
```

::: {.callout-important title="Metadata inconsistencies and Conversion to UIC Units"}

<!-- - [For drug `SBI-0206965`, both `Date` and `Run date` were wrongly reported (either not stored in the proper barcode counts profile, or mistyped in `Table of Compounds`).]{fg="red"} -->

- [In `Run date`, when there was a range instead of a fixed Date, I kept only the end of the interval, as used for labelling colnames in barcode counts.]{fg="red"}

- [Homogenise units for the `Concentrations` colname: convert everything to moles.]{fg="red"}

- [Homogenise units for `Date` and `Run date`, using international ISO 8601 format: `YYYY-MM-DD`]{fg="red"}

:::

In @lst-process-pheno2 and @lst-process-pheno3, we identify which raw barcode counts matrices avalaible in folder `barcode-counts` are not reported in the global experimental dataset, and reciprocally. Finally, we only **keep experiences that are both reported in `Table of compounds` and present in `barcode-counts` folder.**.

```{r}
#| label: process-pheno2
#| lst-label: lst-process-pheno2
#| lst-cap: Identify shared experience IDs between experimental design table (`Table of compounds`), and barcode-count counts profiles.

# keep only relevant files 
barcodes_filenames <- list.files("./data/barcode-counts/",
                                pattern = "^exp.*\\.csv$")

barcodes_IDs <- readxl::read_xlsx("data/Table of compounds.xlsx",
                                       sheet="Batch Mapping") |> 
  select(Filename, Batch_ID) |> 
  filter(!Batch_ID %in% c("exp130921_in vivo", "exp200921", "exp281022")) |> 
  mutate(Filename =paste0(Filename, ".csv"), 
         Date = stringr::str_extract(Batch_ID, "(?<=^exp)[[:digit:]]{6}"))

```


<!-- ::: {.callout-important title="Missing information on Table of Compounds and missing Experiences"} -->

<!-- We note the following inconsistencies: -->

<!-- 1. Using ``{r} setdiff(barcodes_filenames, barcodes_IDs$Filename)``, we note that the following files present in `data-raw` will be excluded: `{r} setdiff(barcodes_filenames, barcodes_IDs$Filename)`. For details, report to @sec-select-exp. -->

<!-- 2. Using ``{r} setdiff(barcodes_IDs$Filename, barcodes_filenames)``, we certified that all remaining filenames in the folder were properly mapped. -->

<!-- 3. Using ``{r} setdiff(pheno_data$Batch_ID, barcodes_IDs$Batch_ID)``, all experiments `{r} paste(setdiff(pheno_data$Batch_ID, barcodes_IDs$Batch_ID), collapse = ", ")` reported in original `Table of Compounds` could have been mapped back to an existing experiment, once `Control - time zero` have been discarded.  -->

<!-- ::: -->

To generate the final phenotype dataset, we only keep experiences that were reported both in `Table of Compounds` and folder `barcode-counts`, and pair `Table of Compounds` with individual replicate IDs in @lst-process-pheno3, based on `Date`, `Run date`, short drug ID and `Concentration` for unequivocal mapping. [**Please ensure that `Drugs Mapping` sheet in [`Table of compounds`](data/Table of compounds.xlsx) is correct.**]{fg="red"}

```{r}
#| label: process-pheno3
#| lst-label: lst-process-pheno3
#| lst-cap: Map each drug to its full list of replicates. Generate a `Batch_ID` to unequivocally ientify each run of experiences, and convert all run Dates to their international format.

# step 1) keep only shared Batch_ID experiences ----
barcodes_IDs <- barcodes_IDs |>
  dplyr::semi_join(pheno_data, by="Batch_ID")
# exp201021 is discarded, that's normal, we just want to keep the controls!!
pheno_data <- pheno_data |>
  dplyr::semi_join(barcodes_IDs, by="Batch_ID")

# step 2) extract individual replicate IDs directly from sample experiences ----
ID_mapping <- purrr::pmap(barcodes_IDs, function(Filename, Batch_ID, Date) {
  # build path
  counts_path <- file.path("data","barcode-counts", 
                               paste0(Filename))
  
  # extract replicate names (reading the header)
  replicates_ID <- strsplit(readLines(counts_path, n = 1), split = ",")[[1]] |>
    str_subset("\\S") |> # remove empty strings and 'key'
    str_subset("barcode_id", negate = TRUE)

  # ID: combination of letters, numbers and -, followed by '[1-4]_', starting the sample's name
  dataset_ID <- tibble::tibble(Batch_ID = Batch_ID, 
                               Date = stringr::str_extract(replicates_ID,
                                                           "(?<=_exp)[[:alnum:]]{6}(?=_run)"),
                               Replicates_ID = replicates_ID,
                               `Run date` = stringr::str_extract(replicates_ID,
                                                                 "(?<=_run)[[:alnum:]]{6}(?=_)"),
                               Concentrations_ID = stringr::str_extract(replicates_ID, 
                                                                        "(?<=[1-8]_)[[:digit:]]{3}[gmnux]{1}(?=_exp)")) |> 
    # account for second notation syntax for concentrations
    dplyr::mutate(Concentrations_ID = if_else(is.na(Concentrations_ID), 
                                              stringr::str_extract(replicates_ID,
                                                                   "(?<=[1-8]_)[0-9]{1}\\.[0-9]{2}[gmnux]{1}(?=_exp)"),
                                              Concentrations_ID))
  
  # Deal with two time notations
  if (grepl("Time",Batch_ID, ignore.case = TRUE)) {
    dataset_ID <- dataset_ID |> 
      dplyr::mutate (Samples_ID = stringr::str_extract(replicates_ID,
                                                       "(?<=_)[[[:alnum:]]\\-]+(?=[1-8]_)"), 
                     Duration_ID=stringr::str_extract(replicates_ID,
                                                       "^[[[:alnum:]]\\.]{1,3}[dm](?=_)"))
  }
  else {
      dataset_ID <- dataset_ID |> 
      dplyr::mutate (Samples_ID = stringr::str_extract(replicates_ID,
                                                       "^[[[:alnum:]]\\-]+(?=[1-8]_)"), 
                     Duration_ID="9d")
  }
                                 
  return(dataset_ID)
}) |>
  purrr::list_rbind()

# step 3) map short drug IDs with full drug names ----
mapping_compounds <- readxl::read_xlsx("data/Table of compounds.xlsx",
                                sheet = "Drugs Mapping")
ID_mapping <- ID_mapping |> inner_join(mapping_compounds, by = "Samples_ID")
# test <- ID_mapping |> anti_join(mapping_compounds, by = "Samples_ID")

```

- `Osimertinb`: in the general Table, concentration used to be reported as `0.10u` versus `100n` as a barcode colname. [I changed directly `Table of Compounds` accordingly, hence the empty table in @tbl-check-pheno-data.]{fg="red"}
<!-- - `Alisertib` experiment from `Date: 220322` is assigned with a `050u` concentration in *counts*, against `050n` in *phenotype data*. -->
<!-- - `Sorafenib` experiment from `Date: 151121` is assigned with a `005u` concentration in *counts*, against `004u` in *phenotype data*. On the other hand, `Sorafenib` experiment from `Date: 300821` with a `005u` concentration in *phenotype data* has been removed in *counts*. -->
<!-- - `X13271` with concentration `005u`, both run on `Run Date: 180821`, have been discarded in *counts*. -->
<!-- [Besides, `protac` (in the latest drug experiment) and `PROTAC` are seem duplicate sample IDs for referring to as the main species `Gefitinib-PROTAC-1`]{fg="red"}. -->

```{r}
#| label: tbl-check-pheno-data
#| lst-label: lst-check-pheno-data-1 
#| lst-cap: "Extract discarded replicates"
#| tbl-cap: Identify set of experiences reported in `Table of compounds` that could not be mapped against their corresponding Barcode counts replicates. We check this information with an `anti_join` between original *phenotype* and *counts*, returning samples from `Table of Compounds` that could not have been mapped back.

pheno_data_unmapped <- dplyr::anti_join(pheno_data,
                                     ID_mapping,
                                     by = c("Batch_ID",  "Samples", "Duration_ID",
                                            "Run date", "Date", "Concentrations_ID"))

pheno_data_unmapped |> 
  anti_join(ID_mapping,
            by = c("Batch_ID",  "Samples", "Date", "Run date", "Concentrations_ID")) |> 
  arrange(Samples, Date, Concentrations_ID) |> 
  flextable() |> 
  bold(part = "header")

replicates_discarded <- dplyr::anti_join(ID_mapping, pheno_data,
                                     by = c("Batch_ID",  "Samples", "Duration_ID",
                                            "Run date", "Date", "Concentrations_ID"))
today_date <- format(Sys.Date(), "%Y-%m-%d")
readr::write_csv(replicates_discarded, 
                 file = paste0("data/discarded_replicates_", today_date,".csv"))
```

In @tbl-check-pheno-data-2, we check discrepancies between the final selection of barcode experiences with the reported number of replicates. [Great point: no discrepancies witnessed, hence the empty table!!]{fg="green"}

```{r}
#| label: tbl-check-pheno-data-2
#| lst-label: lst-check-pheno-data-2
#| lst-cap: Secound round of data wrangling quality controls on *counts* versus *phenotype data*, focusing on divergent number of replicates.
#| tbl-cap: Secound round of data wrangling quality controls on *counts* versus *phenotype data*, focusing on divergent number of replicates.

replicate_inconsistencies <- pheno_data |> 
  dplyr::inner_join(ID_mapping,
                    by = c("Batch_ID", "Date", 
                           "Samples", "Run date",
                           "Concentrations_ID", "Duration_ID")) |>
  group_by(Batch_ID, Samples, Date, Replicates, Concentrations_ID,Duration_ID) |>
  summarise(n=n()) |>
  filter(n!=Replicates)

flextable(replicate_inconsistencies) |>
  autofit() |>
  bold(part = "header")
```

<!-- ::: {.callout-important title="Inconsistent reporting of number of Replicates"} -->

<!-- - In this section, we describe the output of unmet experiences from @tbl-check-pheno-data, that was generated using ``{r} dplyr::anti_join(pheno_data, ID_mapping, by = c("Date", "Samples", "Run date"))``. [Overall, 9 experiences reported in `Table of Compounds` for which we could not find their counterpart replicated experiences directly.]{fg="red"} -->

<!--   1. `Control` paired with `Date: 130921` and `Run date: 101121`: while they are not reported in `exp130921.csv`, it should be associated with `Osimertinb`, `Date: 130921` and `Run date:101121`, all mentioned in file `exp130921_in vivo.csv`. -->

<!--   2. Turned out that `Osimertinb`, with `Date: 200921` and `Run date:101121`, is to be associated with `exp200921_dose response osim.csv`. [Major issue: the control IDs of this experiment are the same reported in `exp200921.csv`, while the barcode tag names differ. Is this a distinct batch?]{fg="red"} -->

<!--   3. [`Sorafenib` with `Date: 300821` and `Run date:290921` could not be find anywhere, as well as `X13271` for `Date: 010821`, `Date: 040821` and `Run date:180821`]{fg="red"}. -->

<!-- - **Good point**: we were able to map each individual `Replicates_ID` to its input value in `Table of compounds`. -->

<!-- - [On the other hand, we note an inconsistent number of replicates associated with compound `XAV-939`]{fg="red"}. Indeed, on the original `Table of compounds` table, **4 replicates** are reported for that experiment, against **2 reported** in Barcode-counts counts matrix `exp220322.csv`, at Date the 22th of March, 2022. -->

<!-- ::: -->

### Phenotypes metadata: Final Table generation

By applying all the formatting analyses reported in @sec-metadata-phenotypes, we generate in @tbl-phenotype-metadata-saving a global metadata phenotypic table, adhering to tidy principles [@tip-tidyformat]. [Note that I renamed some colnames, better fitting usual naming conventions:        `Level1` by `Pathway`, `Level2` by `MoA` (for mechanism of action ), and `Samples` by `Compound`.]

::: {#tip-tidyformat .callout-tip title="Tidy Data Format (Key Principles)" collapse="true"}

1. **Each variable has its own column**.
2. **Each observation has its own row** – Every row corresponds to one observation.
3. **Each value has its own cell** – Each cell contains a single, unique value.

This format streamlines data wrangling, and generally speaking, data analysis and visualisation. In other words, prefer simpler `CSV` formats for the experimental design, and avoid *cell fusion* in Excel documents. Finally, for the formatted tabular representation in documentations, I use `flextable`.

:::

```{r}
#| label: tbl-phenotype-metadata-saving
#| lst-label: lst-save-pheno-metadata
#| lst-cap: Save the final metadata annotations for barcodes, using Today's date for historical versioning.

# step 4) Use international date formats ----
pheno_data_formatted <- pheno_data |> 
  dplyr::inner_join(ID_mapping,
                    by = c("Batch_ID", "Date", 
                           "Samples", "Run date",
                           "Concentrations_ID", "Duration_ID")) |> 
  dplyr::select(Batch_ID,
                # samples names
                Pathway=Level1, MoA=Level2,
                Compound=Samples, Samples_ID,
                Replicates, Replicates_ID,
                # replicate features
                Concentrations, Concentrations_ID, 
                Date, `Run date`, Duration, Duration_ID) |> 
  # convert to ISO 1860 Date format
  mutate(Date = lubridate::dmy(Date) |> format(),
         `Run date`= lubridate::dmy(`Run date`))

# step 5) save the tidy phenotype metatada table ----
today_date <- format(Sys.Date(), "%Y-%m-%d")
readr::write_csv(pheno_data_formatted,
                 file = paste0("data/pheno_data_metadata_", today_date,".csv"))

flextable::flextable(head(pheno_data_formatted)) |> 
  autofit() |> 
  bold(part="header")
```


**Conclusion**: on a total of `{r} nrow(ID_mapping)`, `{r} nrow(pheno_data_formatted)` replicates are kept, and `{r} nrow(replicates_discarded)` replicates were filtered out, based on Luca's guidelines.

# Analyses

## Preprocessing barcode counts{#sec-batch-processing}

**Code colour**: [Luca's protocol]{fg="blue"}, and [Bastien's comments and perspectives]{fg="red"}

### **Background Noise Removal** and `SummarizedExperiment` stantardised storage

-   [Eliminate barcodes for which the combined counts of the 4 controls per barcode are below a given threshold, here `5`.]{fg="blue"} [Temporaly exclude file `./data/barcode-counts/exp200921_dose response osim.csv`, as the filtering does not return any barcode.]{fg="red"}

```{r}
#| label: background-filtering
#| lst-label: lst-background-filtering
#| lst-cap: Remove background noise.

barcode_files <- list.files("./data/barcode-counts/",
                            pattern = "exp.*\\.csv",
                            full.names = TRUE)
thresh_background <- 4
pheno_data <- readr::read_csv("./data/pheno_data_metadata_2025-04-17.csv")
# filename <- barcode_files[6]

# explicit and data-sound but unefficient code
barcode_counts_aggregated <- purrr::map(barcode_files, function(filename) {
  barcode_counts <- readr::read_csv(filename)
  experience_name <- filename |> basename() |> tools::file_path_sans_ext()
  replicates_names <- setdiff(colnames(barcode_counts), "barcode_id")
  
  ## Remove lowly expressed barcodes ----
  control_index <- pheno_data |> 
    dplyr::filter(Batch_ID==experience_name & 
                    Compound=="Control" &
                    Replicates_ID %in% replicates_names) |> 
    dplyr::pull(Replicates_ID)
  signicant_barcodes_index <- which(rowSums(barcode_counts[, control_index]) > thresh_background)
  filtered_barcode_counts <- barcode_counts[signicant_barcodes_index,]
  return(filtered_barcode_counts)
}) |> 
  purrr::reduce(~ inner_join(.x, .y, by = "barcode_id"))
```


-   [Density plots to evaluate the relevance of this threshold, `HTSFilter`, comparison with existing filtering approaches, ... But removing noise is indeed a great point!!, especially with the original high number of barcodes. However, why only performing this operation on control cases?]{fg="red"}

### **Normalisation**

-   [Normalize barcodes so that the total number of counts per sample is 100 000]{fg="blue"}

```{r}
#| label: cpm-normalisation
#| lst-label: lst-cpm-normalisation
#| lst-cap: Normalise by $100000$.
replicates_names <- setdiff(colnames(barcode_counts_aggregated),
                            "barcode_id") # alternatively, select numeric values

barcode_counts_aggregated <- barcode_counts_aggregated |> 
  mutate(across(
    .cols = where(is.numeric),                     
    .fns = ~ (.x / sum(.x)) * 1e5
  ))
```


-   [Close to two existing normalisation methods: **Counts Per Million (CPM)** which additionally scales raw counts by total library size and multiplies by $1,000,000$ and **Total Count Scaling (TCS)**: Scales raw counts by the total number of reads (or mapped reads) in each sample, then multiplies by a fixed number (e.g., 100,000). Would compare other normalisation approaches + ignore biological or technical biases + generate MA plots for verifying the mean-variance correction trend + not suitable for DEG analyses. Apply concatenation phase of all samples before normalising. Comprehensive discussion on the impact of distinct normalisation approaches [here](https://www.linkedin.com/posts/%F0%9F%8E%AF-ming-tommy-tang-40650014_rna-seq-normalization-what-you-need-to-activity-7313919533780516864-6jFm).]{fg="red"}

### **Differential analyses** and Binarisation

1. [Calculate mean of the 4 controls, followed by **Differential Represented Barcode Analysis**: binarise each replicate, assining a 1 if Fold change is above 3 with respect to Mean value, and 0 otherwise.]{fg="blue"} [Batch effect correction for integrating across batches? As Vera emphasised it out, why keeping only positive values? Negative are also interesting, otherwise, we will bias towards drugs having a positive fitness. Why not pairing $p$-values and fold-change (considering indeed really small sample sizes)? All these operations can be run within one step using `lm`, and a model as such, $\text{Expr} \sim 0 + \text{Gene} + \text{Batch} + \text{Drug}$, with a `contr.treatment` design matrix [^1]]{fg="red"}.

```{r}
#| label: differential-barcode-analysis
#| lst-label: lst-differential-barcode-analysis
#| lst-cap: Compute the averaged basal value, .

barcode_counts_long <- barcode_counts_aggregated |> 
  tidyr::pivot_longer(-barcode_id, names_to = "Replicates_ID", values_to = "Barcode_Counts") |> dplyr::inner_join(pheno_data, by="Replicates_ID") |> 
  dplyr::select(-Pathway, -MoA, -Samples_ID, -Replicates, -Concentrations_ID, -Duration_ID)
threshold_FC <- 3

# Step 1: Compute control means per barcode_id and Batch ----
control_means <- barcode_counts_long |>
  filter(Compound == "Control") |>
  group_by(Batch_ID, barcode_id) |>
  summarise(Control_Mean = mean(Barcode_Counts), .groups = "drop")

# Step 2: Join control mean to full dataset ----
barcode_counts_discretised <- barcode_counts_long |>
  left_join(control_means, 
            by = c("Batch_ID","barcode_id"))

# Step 3: Compute Fold Change and discretise ----
barcode_counts_discretised <- barcode_counts_discretised |>
  filter(Compound != "Control") |>
  mutate(Diff = Barcode_Counts - Control_Mean,
    Barcode_Counts = if_else(Diff > threshold_FC, 1, 0)) |>
  # Final cleanup 
  select(-Diff, -Control_Mean)  |> 
  dplyr::mutate(Barcode_Counts=as.logical(Barcode_Counts))
```


[^1]: [Really wants to try the **Helmert contrast** to evaluate drug dose response, or time-course studies. Also For repeated measures across time, see [One Way repeated measure ANOVA in R](https://www.r-bloggers.com/2025/02/one-way-repeated-measure-anova-in-r/)]{fg="red"}

### **Derivation of drug fingerprints**:

[Aggregate by drug and experience.]{fg="blue"} [Efficient computation of binary values with a logical `AND` + perform **sensitivity analyses** to evaluate the impact of threshold variation.]{fg="red"}


```{r}
#| label: drug-fingerprint-estimation
#| lst-label: lst-drug-fingerprint-estimation
#| lst-cap: "Aggregate at the drug level, assigning a 1 if, and only if, barcode cell lines were found significant in a given drug."

barcode_counts_discretised_drug <- barcode_counts_discretised |> 
  group_by(Batch_ID, Concentrations, Duration, Date, `Run date`, barcode_id, Compound) |> 
  summarise(Barcode_Counts = all(Barcode_Counts == 1), .groups = "drop")


barcode_counts_discretised_replicates <- barcode_counts_discretised |> 
  select(-Concentrations, -Duration, -Date, -`Run date`, -Batch_ID, -Compound) |> 
  tidyr::pivot_wider(names_from = Replicates_ID, values_from = Barcode_Counts)
saveRDS(barcode_counts_discretised_replicates, 
        file="results/fingerprints_replicates_level.rds")

barcode_counts_discretised_drug <- barcode_counts_discretised_drug |> 
  dplyr::mutate(Compound=paste0("Drug: ", Compound, " with Batch: ", Batch_ID,
                                ", Conc: ", Concentrations, " and Days: ", Duration)) |> 
  select(-Concentrations, -Duration, -Date, -`Run date`, -Batch_ID) |> 
  tidyr::pivot_wider(names_from = Compound, values_from = Barcode_Counts)

saveRDS(barcode_counts_discretised_drug, 
        file="results/fingerprints_compounds_level.rds")
```


## Compute Drug Similarities

1. [Actual computation of the correlation matrix using `stats::cor`.]{fg="blue"} [Yet, we have to try other correlation methods on the continuous space, or consider other metrics if working on the discrete space. Unbalanced Wassertein distance, or relatives, for distinct input and output dimensions.]{fg="red"}

```{r}
#| label: convert-to-matrices
barcode_replicates_mat <- barcode_counts_discretised_replicates |> 
  tibble::column_to_rownames(var="barcode_id") |> 
  as.matrix()
cor_replicates <- cor(barcode_replicates_mat)


barcode_drugs_mat <- barcode_counts_discretised_drug |> 
  tibble::column_to_rownames(var="barcode_id") |> 
  as.matrix()
cor_drugs <- cor(barcode_drugs_mat)
```


2. Plot weighted undirected graphs with `igraph::graph_from_adjacency_matrix`
    
## Compute Barcode aka Cell Lines Similarities

[To select barcodes highly correlated within each other, must correlate, with $CC > 0.8$ with at least 4 others.]{fg="blue"}.

# Results

## Correlation Heatmaps

- [Blend of useful resources on generating Heatmaps](https://www.linkedin.com/posts/%F0%9F%8E%AF-ming-tommy-tang-40650014_making-a-heatmap-is-an-essential-skill-for-activity-7317543424511868928-F25t)

- Heamaps at the drug and replicate level are reported in @fig-generate-heatmap-drug.

```{r}
#| label: fig-generate-heatmap-drug
#| fig-cap: "Heamaps at the drug and replicate level."
# define clustering colours
col_cor_scale <- circlize::colorRamp2(c(-1, 0, 1), c("blue", "white", "red"))

heatmap_drugs <- ComplexHeatmap::Heatmap(cor_drugs, col=col_cor_scale)
heatmap_replicates <- ComplexHeatmap::Heatmap(cor_replicates, col=col_cor_scale)

p1 <- grid.grabExpr(ComplexHeatmap::draw(heatmap_drugs))
p2 <- grid.grabExpr(ComplexHeatmap::draw(heatmap_replicates))
heatmaps_global <- plot_grid(p1, p2, nrow = 1, labels = c("A", "B"))
ggsave("figures/heatmap_fingerprints.pdf", 
       heatmaps_global, dpi = 600)

heatmaps_global
```

# Perspectives

## Integrate Single Cell Analyses

- [Single cell and drug response largest database](https://www.linkedin.com/posts/independent-data-lab_check-out-the-preprint-activity-7300471798029012993-YRjy)
- [Biologist perspective](https://docs.google.com/document/d/1UHD6IG9Rti2tD77zwHfSyh5XyTbnJ25S/edit)
- - Single-cell lineage capture across genomic modalities with `CellTag-multi` reveals fate-specific gene regulatory changes -> use of **single-cell lineage-tracing (scLT)**. 
- High-resolution, noninvasive single-cell lineage tracing in mice and humans based on DNA methylation epi-mutations.

## Pipeline tracks of improvement

### `bartools` and `BARtab`

- Analysis of synthetic cellular barcodes in the genome and transcriptome with `BARtab` and `bartools`. 

### DEBRA

- Pros `DEBRA`
  - Better characterisation of the mean-variance deviation -> between `trended` or `shrinkage`, `trended` is favoured.

- Cons `DEBRA`:
  - `DEBRA` does not account for outliers expression, nor zero-inflated counts -> recommendation of `glmQLFit` and `glmQLFTest` for routine GLM-based DE analyses, from [`EdgeR`: Explaning dispersion types to newbies](https://support.bioconductor.org/p/110273/).
  - Complex protocol for discarding lowly differentially expressed barcodes.
  - No available BioConductor/CRAN Repository, while latest [`DEBRA` GitHub update](https://github.com/YevhenAkimov/DEBRA_1.01) dates back more than 4 years.

### Drug clustering and mapping

- Use of graph clustering approaches? Like Louvain? + multiple case studies, how to combine them (2 vials of cell lines)?
- Compare with ATC prediction and clustering: [`PDATC-NCPMKL-updated` GH Repo](https://github.com/Lywhere/PDATC-NCPMKL-updated).


# TODO

- Tools:
  - Computational resources (create a dedicated project on the IFB core cluster?)

# Appendix {.appendix}

## Publish cell lines on Web repositories

- [`cellosaurus` General Comments](https://www.expasy.org/resources/cellosaurus) and [`cellosaurus` Official Website](https://www.cellosaurus.org/), from[@bairoch2018jbt; @robin2020ijc]. Specifically, the `CLASTR` algorithm relies on *short-tandem repeat* patterns to map user-provided cell lines with the ones available in `Cellosaurus` database.
- [`Bgee`](https://www.bgee.org/), from [@bastian2021nar; @bastian2025nar].

<!-- ## Mapping short and full samples IDs {#sec-ID-mapping} -->

<!-- In @lst-process-pheno3-appendix, we provide a semi-supervised approach to map short drug IDs in barcode expression colnames to their respective full drug IDs counterparts in `Table of Compounds`. -->

<!-- ```{r} -->
<!-- ID <- "281022" -->
<!-- expression_path <- file.path("data", "data-raw", -->
<!--                              "barcode-counts", paste0("exp", ID, ".csv")) -->

<!-- replicates_ID <- strsplit(readLines(expression_path, n = 1), split = ";")[[1]] |> -->
<!--   str_subset("\\S") |> # remove empty colnames, notably the identifier -->
<!--   str_subset("key", negate = TRUE) # remove any value exactly equal to key -->

<!-- dataset_ID <- tibble::tibble( -->
<!--   Date = ID, -->
<!--   Replicates_FullID = replicates_ID, -->
<!--   Replicates_ID = stringr::str_extract(replicates_ID, "^[[[:alnum:]]\\-]+(?=[1-4]_)")) -->
<!-- ``` -->


<!-- ```{r} -->
<!-- #| label: process-pheno3-appendix -->
<!-- #| lst-label: lst-process-pheno3-appendix -->
<!-- #| lst-cap: Semi-automated approach to map short drug or control ID to full Drug ID, stored in column `Samples`. To fully automate this approach, pair `agrep` with explicit computation of the **generalized Levenshtein edit distance**, as there's no unambiguous 1-1 mapping between short sample IDs and full sample IDs. -->
<!-- #| eval: false -->

<!-- ID_mapping <- lapply(barcode_ID, function(ID) { -->
<!--   # build path -->

<!--   expression_path <- file.path("data", "data-raw", "barcode-counts", paste0("exp", ID, ".csv")) -->

<!--   replicates_ID <- strsplit(readLines(expression_path, n = 1), split = ";")[[1]] |> -->
<!--     str_subset("\\S") |> # remove empty colnames, notably the identifier -->
<!--     str_subset("key", negate = TRUE) # remove any value exactly equal to key -->

<!--   # build dataset ID, ID seems to be any combination of letters, numbers and -, followed by [1-4]_ -->

<!--   dataset_ID <- tibble::tibble( -->
<!--     Date = ID, -->
<!--     Replicates_FullID = replicates_ID, -->
<!--     Replicates_ID = stringr::str_extract(replicates_ID, "^[[[:alnum:]]\\-]+(?=[1-4]_)") -->
<!--   ) -->

<!--   # unfortunatly, it turned out it was even more complex, so add an extra-step for matching the closest ID matching column `Samples` -->

<!--   Replicates_ID2 <- sapply(dataset_ID$Replicates_ID, function(ID_mapping) { -->
<!--     ID_pheno <- grep(paste0("^", ID_mapping), unique(pheno_data$Samples), -->
<!--       ignore.case = TRUE, value = TRUE -->
<!--     ) # alternative: agrep -->

<!--     #  deal with three potential scenarios -->

<!--     if (length(ID_pheno) == 0L) { -->
<!--       message(paste("Find no correspondance for", ID_mapping, ".\n")) -->

<!--       return(NA) -->
<!--     } else if (length(ID_pheno) > 1L) { -->
<!--       message(paste0( -->
<!--         "Find more than one correspondance for ", ID_mapping, -->
<!--         ", namely ", paste(ID_pheno, collapse = ", "), " . Select the first one.\n" -->
<!--       )) -->
<!--     } -->

<!--     return(ID_pheno[1]) -->
<!--   }) -->

<!--   dataset_ID <- dataset_ID |> -->
<!--     mutate(Replicates_ID2 = Replicates_ID2) -->

<!--   return(dataset_ID) -->
<!-- }) |> -->
<!--   dplyr::bind_rows() -->

<!-- ID_mapping |> -->
<!--   filter(!is.na(Replicates_ID2)) |> -->
<!--   distinct(Replicates_ID, Replicates_ID2) |> -->
<!--   openxlsx::write.xlsx("mapping_species.xlsx") -->
<!-- ``` -->
