---
title: "Methods: normalise, identify DRBs and save as `SummarizedExperiment` objects"
---

## Reproducibility

I list below the R packages required to reproduce the analyses.

```{r}
#| label: setup

## data wrangling
library(dplyr)
library(tidyr)
library(stringr)
library(readr)
library(readxl)
library(purrr)

## plotting
library(ggplot2)

## reporting
library(flextable)

# automated package linting
library(xml2)
library(downlit)

## auxiliary functions
source("R/utils.R")
today_date <- "2025-06-13"
## today_date <- format(Sys.Date(), "%Y-%m-%d")

## set the seed, for fixing generation of ComplexHeatmaps (dendogram clustering)
set.seed(20)
```

**Code colour**: [Luca's protocol]{fg="blue"}, and [Bastien's comments and perspectives]{fg="red"}

## Import barcode counts to standardised BioConductor formats

- Read all barcode profiles, and merge them together based on shared `barcode_id`.

```{r}
#| label: import-barcode-counts-and-merge-them
#| lst-label: lst-import-barcode-counts-and-merge-them
#| lst-cap: Import all raw barcode `.tsv` files, and add artificial controls for experiment `exp200921_dose_response`.

pheno_data <- readr::read_csv(paste0("./data/replicates_barcode_metadata_",
                                     today_date, ".csv"), 
                              show_col_types = FALSE) 
barcode_files <- unique(pheno_data$Filename)

## 1) artificially add duplicated metadata ----
artificial_controls_metadata <- pheno_data |>
  dplyr::filter(Compound == "Control" & Batch_ID == "exp200921") |>
  dplyr::mutate(Batch_ID = "exp200921_dose_response", 
                Replicates_ID = gsub("run111021", "run101121", Replicates_ID))
pheno_data <- pheno_data |>
  dplyr::bind_rows(artificial_controls_metadata) |> 
  # add a unique column per compound and biological condition
  dplyr::mutate(Unique_compound = paste0(Compound, "_", Batch_ID, "_",
                                        "Conc: ", Concentrations_Formatted, "_",
                                        "Days: ", Duration, sep = "_"))

barcode_counts_aggregated <- purrr::map(barcode_files, function(filename) {
  barcode_filepath <- file.path("./data/barcode-counts", filename)
  barcode_counts <- readr::read_tsv(barcode_filepath, 
                                    show_col_types = FALSE)
  
  ## 2) artificially add duplicated control samples for dose-response ----
  if (filename == "exp200921.tsv") {
    barcode_duplicated_controls <- barcode_counts |> 
      dplyr::select("barcode_id", dplyr::matches("^Contro(.*)_000u_exp200921_run111021_")) |> 
      dplyr::rename_with(
        .fn = ~ gsub("run111021", "run101121", .x),
        .cols = starts_with("Contro"))
    
    barcode_counts <- barcode_counts |> 
      dplyr::inner_join(barcode_duplicated_controls, by = "barcode_id")
  }
  
  return(barcode_counts)
}) |> 
  purrr::reduce(~ inner_join(.x, .y, by = "barcode_id"))

## 3) check that we can map each barcode replicate to its corresponding metadata information
stopifnot(identical(setdiff(pheno_data$Replicates_ID, colnames(barcode_counts_aggregated)), character(0)))
gc()
```


The resulting barcode counts matrix stores `{r} length(unique(barcode_counts_aggregated$barcode_id))` unique **barcode IDs**, and `{r} ncol(barcode_counts_aggregated)-1` unique replicates (with 4 artificially duplicated controls for dose response).


### Generating a `DGEList` object from sample counts and metadata

- Export to `EdgeR::DGEList` format.

```{r}
#| label: export-DGEList
#| lst-label: lst-export-DGEList
#| lst-cap: Export to `DGEList` format.

# prepare barcode counts ----
counts <- barcode_counts_aggregated |> 
  tibble::column_to_rownames("barcode_id") |> 
  as.matrix()
## ensure consistent order
counts <- counts[, pheno_data$Replicates_ID]

samples <- pheno_data |> 
  tibble::column_to_rownames("Replicates_ID")
dge_count <- edgeR::DGEList(counts = counts, 
                            samples = samples, 
                            group = samples$Compound,
                            remove.zeros = TRUE)
saveRDS(dge_count, 
        paste0("./data/processed/DGEList_before_filtering_", today_date, ".rds"))

```

### Generating a `SummarizedExperiment` object from sample counts and metadata

```{r}
#| label: export-SummarizedExperiment
#| lst-label: lst-export-SummarizedExperiment
#| lst-cap: Export to `SummarizedExperiment` format.

barcode_metadata <- tibble::tibble(barcode_id = row.names(counts))
row.names(barcode_metadata) <- row.names(counts)

summarized_before_filtering <- SummarizedExperiment::SummarizedExperiment(
  assays = list(counts = counts),
  rowData = barcode_metadata,
  colData = samples)

saveRDS(summarized_before_filtering, 
        paste0("./data/processed/SummarizedExperiment_before_filtering_", today_date, ".rds"))

rm(artificial_controls_metadata, barcode_counts_aggregated,
   barcode_metadata, counts, samples, pheno_data, barcode_files)
```

## Barcode quality controls

In this section, we use `bartools::thresholdCounts()` to determine an appropriate threshold to maximise signal to noise and retain the most informative barcodes. 

### Remove barcodes with no information

- Remove barcode IDs with only null values. All kept barcode IDs contain at least one non-null value: 

```{r}
#| label: remove-null-rows
dge_count <- readRDS(paste0("./data/processed/DGEList_before_filtering_", today_date, ".rds"))
dge_count <- dge_count[rowSums(dge_count$counts) != 0, ]
```

### Background noise filtering

#### Background noise filtering based on absolute levels

- Filter out based on a minimal absolute threshold of barcode in a minimal number of samples by `Compound`:

```{r}
#| label: background-filtering-absolute-compound
#| include: true


dge_filtered_absolute_1_N_1_by_compound <- bartools::thresholdCounts(
  dge_count,
  threshold = 1,
  minSamples = 1,
  plot = TRUE,
  group = "Compound") +
  theme(legend.position = "bottom")

dge_filtered_absolute_10_N_1_by_compound <- bartools::thresholdCounts(
  dge_count,
  threshold = 10,
  minSamples = 1,
  plot = TRUE,
  group = "Compound") +
  theme(legend.position = "bottom")

dge_filtered_absolute_10_N_5_by_compound <- bartools::thresholdCounts(
  dge_count,
  threshold = 10,
  minSamples = 5,
  plot = TRUE,
  group = "Compound") +
  theme(legend.position = "bottom")


dge_filtered_compounds_plots <- gridExtra::marrangeGrob(grobs = list(alpha1_N1 = dge_filtered_absolute_1_N_1_by_compound, 
                                                                     alpha10_N1 = dge_filtered_absolute_10_N_1_by_compound, 
                                                                     alpha10_N5 = dge_filtered_absolute_10_N_5_by_compound), 
                                                        nrow = 1, ncol = 1, top = "Plotting absolute barcode counts by compound, after applying filtering.")

ggsave("./figures/barcode_filtering/dge_filterered_absolute_Compounds.pdf", 
       dge_filtered_compounds_plots, dpi = 600, width = 14, height = 14)

```



- Filter out based on a minimal absolute threshold of barcode in a minimal number of samples by `Batch_ID`:

```{r}
#| label: background-filtering-absolute-batch
#| include: true

dge_filtered_absolute_1_N_1_by_batch <- bartools::thresholdCounts(
  dge_count,
  threshold = 1,
  minSamples = 1,
  plot = TRUE,
  group = "Batch_ID") +
  theme(legend.position = "bottom")

dge_filtered_absolute_10_N_1_by_batch <- bartools::thresholdCounts(
  dge_count,
  threshold = 10,
  minSamples = 1,
  plot = TRUE,
  group = "Batch_ID") +
  theme(legend.position = "bottom")

dge_filtered_absolute_10_N_5_by_batch <- bartools::thresholdCounts(
  dge_count,
  threshold = 10,
  minSamples = 5,
  plot = TRUE,
  group = "Batch_ID") +
  theme(legend.position = "bottom")

dge_filtered_batches_plots <- gridExtra::marrangeGrob(list(alpha1_N1 = dge_filtered_absolute_1_N_1_by_batch, 
                                                           alpha10_N1 = dge_filtered_absolute_10_N_1_by_batch, 
                                                           alpha10_N5 = dge_filtered_absolute_10_N_5_by_batch), 
                                                      nrow = 1, ncol = 1, 
                                                      top = "Plotting absolute barcode counts by Batch ID, after applying filtering.")

ggsave("./figures/barcode_filtering/dge_filterered_absolute_Batches.pdf", 
       dge_filtered_batches_plots, dpi = 600, width = 14, height = 14)
```


#### Background noise filtering based on relative levels

```{r}
#| label: background-filtering-relative-batch
#| include: true

dge_filtered_relative_0.0001_N_10_by_batch <- bartools::thresholdCounts(
  dge_count,
  type = "relative",
  threshold = 1e-4,
  minSamples = 10,
  plot = TRUE,
  group = "Batch_ID") +
  theme(legend.position = "bottom")

dge_filtered_relative_0.001_N_10_by_batch <- bartools::thresholdCounts(
  dge_count,
  type = "relative",
  threshold = 1e-3,
  minSamples = 10,
  plot = TRUE,
  group = "Batch_ID") +
  theme(legend.position = "bottom")

dge_filtered_relative_0.01_N_10_by_batch <- bartools::thresholdCounts(
  dge_count,
  type = "relative",
  threshold = 1e-2,
  minSamples = 10,
  plot = TRUE,
  group = "Batch_ID") +
  theme(legend.position = "bottom")

dge_filtered_batches_plots <- gridExtra::marrangeGrob(list(alpha0.0001_N10 = dge_filtered_relative_0.0001_N_10_by_batch, 
                                                           alpha0.001_N10 = dge_filtered_relative_0.001_N_10_by_batch, 
                                                           alpha0.01_N10 = dge_filtered_relative_0.01_N_10_by_batch), 
                                                      nrow = 1, ncol = 1, 
                                                      top = "Plotting relative barcode counts by Batch ID, after applying filtering.")

ggsave("./figures/barcode_filtering/dge_filterered_relative_Batches.pdf", 
       dge_filtered_batches_plots, dpi = 600, width = 14, height = 14)
```

```{r}
#| label: background-filtering-final-selection
#| include: true

# cleaning 
rm(list = ls(pattern = "filtered"))
gc()
# final filtering selection
dge_filtered <- bartools::thresholdCounts(dge_count,
                                          type = "relative",
                                          threshold = 1e-4,
                                          minSamples = 10,
                                          plot = FALSE) 
saveRDS(dge_filtered, 
        paste0("./results/dge_filtered_", today_date, ".rds"))

```

### Normalisation

- [We used `TMM` normalisation rather than `CPM` normalisation as proposed in the `bartools` vignette, this technique being better fitted for visualisation purposes (but may require further $\log$ transformation).]{fg="red"}

- [Finally, `tmm` normalisation does not work!!]{fg="red"}

- [Even better, and recommended by Anaïs, apply `vst` or `rlog` transformation from `DeSeq2` package.]{fg="red"}. [Bonus: does not require pre-log transformation!!]{fg=green}. But not proposed by default in the vignette!!

```{r}

dge_cpm <- bartools::normaliseCounts(dge_filtered, method = "CPM")

# raw counts per sample
dge_filtered_plot_compound <- 
  bartools::plotReadCounts(dge_filtered, group = "Compound") +
  theme(legend.position = "bottom")
dge_filtered_plot_batch <- 
  bartools::plotReadCounts(dge_filtered, group = "Batch_ID") +
  theme(legend.position = "bottom")

# normalised counts per sample
dge_normalised_plot_compound <- 
  bartools::plotReadCounts(dge_cpm, group = "Compound") +
  theme(legend.position = "bottom")
dge_normalised_plot_batch <- 
  bartools::plotReadCounts(dge_cpm, group = "Batch_ID") +
  theme(legend.position = "bottom")

# normalisation effect
barplots_normalisation <- cowplot::plot_grid(
  dge_filtered_plot_compound, dge_filtered_plot_batch,
  dge_normalised_plot_compound, dge_normalised_plot_batch,
  labels = "AUTO",
  align = "hv", axis = "tblr", 
  nrow = 2, ncol = 2)

ggsave("./figures/barcode_filtering/dge_barplots_normalisation.pdf", 
       barplots_normalisation, dpi = 300, width = 20, height = 20)
```

### Identify potentially duplicated (or more!!) MOIs

- [Have to redo the function from scratch, to return a proper `ggplot2` object]{fg="red"}

```{r}
#| label: capture-high-MOIs


bartools::plotBarcodeCounts(dge_cpm, log10 = FALSE)
bartools::plotBarcodeCounts(dge_cpm, 
                            log10 = TRUE)
bartools::plotBarcodeCounts(dge_cpm, 
                            order = TRUE,
                            log10 = FALSE)
bartools::plotBarcodeCounts(dge_cpm, 
                            log10 = TRUE, 
                            order = TRUE)

# high_MOI_detection <- cowplot::plot_grid(p1, p2, p3, p4,
#                                          labels = "AUTO",
#                                          align = "hv", axis = "tblr", 
#                                          nrow = 2, ncol = 2)

# ggsave("./figures/barcode_filtering/dge_duplicated_transduction.pdf", 
#        high_MOI_detection,
#        dpi = 300, width = 20, height = 20)
```

### Check correlation between PCR replicates

#### Scatter plots for correlation trends

```{r}
#| label: scatter-plot-correlations


unique_samples <- unique(dge_filtered$samples$Unique_compound)

# Plot all scatter plots per biological replicate
scatter_plots_correlation <- lapply(unique_samples[1], function(x) {
  # subset dge object to get replicates of sample
  replicate_names <- colnames(dge_filtered)[dge_filtered$samples$group %in% as.character(x)]
  bartools::plotBarcodeRegression(dge_filtered,
                                  sample1 = replicate_names[1],
                                  sample2 = replicate_names[2],
                                  rug = TRUE,
                                  trendline = TRUE,
                                  trans = "log1p")
})

barcode_regression_scatter_osim3m_1vs_3 <- bartools::plotBarcodeRegression(
  dge_filtered,
  sample1 = "3m_osim1_100n_exp180123_run110723_41",
  sample2 = "3m_osim4_100n_exp180123_run110723_44",
  rug = TRUE,
  trendline = TRUE,
  trans = "log1p")

ggsave("./figures/scatter-plots-correlation/osim3m_1vs_3.pdf",
       barcode_regression_scatter_osim3m_1vs_3,
       dpi = 300, width = 12, height = 12)

barcode_regression_scatter_osim3m_1vs_2 <- bartools::plotBarcodeRegression(
  dge_filtered,
  sample1 = "3m_osim1_100n_exp180123_run110723_41",
  sample2 = "3m_osim2_100n_exp180123_run110723_42",
  rug = TRUE,
  trendline = TRUE,
  trans = "log1p")

ggsave("./figures/scatter-plots-correlation/osim3m_1vs_2.pdf",
       barcode_regression_scatter_osim3m_1vs_2,
       dpi = 300, width = 12, height = 12)


barcode_regression_scatter_osim3m_1vs_2_notransfo <- bartools::plotBarcodeRegression(
  dge_filtered,
  sample1 = "3m_osim1_100n_exp180123_run110723_41",
  sample2 = "3m_osim2_100n_exp180123_run110723_42",
  rug = TRUE,
  trendline = TRUE,
  trans = NULL)

ggsave("./figures/scatter-plots-correlation/osim3m_1vs_2_no_transfo.pdf",
       barcode_regression_scatter_osim3m_1vs_2_notransfo,
       dpi = 300, width = 12, height = 12)
```


#### Correlation between replicates using `ggplot2`:

- [TODO: compute by batch, and remove replicates poorly correlated]{fg="red"}

```{r}
#| label: pearson-correlation-replicate
# Pearson correlation
dge_filtered_time_course <- dge_filtered[, 
                              dge_filtered$samples$Batch_ID %in% c("exp281022_time_course")]

heatmap_pearson_correlation <- bartools::plotBarcodeCorrelation(dge_filtered_time_course,
                                                                clustered = TRUE,
                                                                upper = FALSE,
                                                                method = "pearson")
ggsave(heatmap_pearson_correlation,
       filename = paste0("figures/correlation-heatmaps/heatmap-pearson-correlation-replicates-time-course-", today_date,".pdf"),
       dpi = 300,
       width = 14, height = 14)



unique_batches <- unique(dge_filtered$samples$Batch_ID)
heatmap_pearson_correlation_plots <- lapply(unique_batches, function(x) {
  dge_filtered_per_batch <- dge_filtered[, 
                                           dge_filtered$samples$Batch_ID == x]
  
  heatmap_correlation_per_batch <- bartools::plotBarcodeCorrelation(dge_filtered_per_batch,
                                                                    clustered = TRUE,
                                                                    upper = FALSE,
                                                                    method = "pearson") +
    labs(subtitle = paste("Batch ID:", x))
  return(heatmap_correlation_per_batch)
})
names(heatmap_pearson_correlation_plots) <- unique_batches

heatmap_pearson_correlation_plots <- gridExtra::marrangeGrob(grobs = heatmap_pearson_correlation_plots, 
                                                             ncol = 1, nrow = 1)

ggsave(heatmap_pearson_correlation_plots,
       filename = paste0("figures/correlation-heatmaps/heatmap-pearson-correlation-all-", today_date,".pdf"),
       dpi = 300,
       width = 14, height = 14)
```

```{r}
#| label: spearman-correlation-replicate
# Spearman correlation
heatmap_spearman_correlation <- bartools::plotBarcodeCorrelation(dge_filtered_time_course,
                                                                clustered = TRUE,
                                                                upper = FALSE,
                                                                method = "spearman")
ggsave(heatmap_spearman_correlation,
       filename = paste0("figures/correlation-heatmaps/heatmap-spearman-correlation-replicates-time-course-", today_date,".pdf"),
       dpi = 300,
       width = 14, height = 14)
```

#### Compute correlation scores among replicates

```{r}
#| label: correlation-per-biological-replicates
corrs_replicates_all <- bartools::calcReplicateCorr(dge_filtered,
                                     corrThreshold = 0.9,
                                     method = "spearman",
                                     ignoreZero = TRUE,
                                     group = "Unique_compound")
corrs[which(corrs < 0.999)]
```

### Collapse PCR replicates

- [Recommended to use the `sum` instead of the mean for sparse data, advised by both Anais and Mark Robinson]{fg="red"}

```{r}
#| label: collapse-replicates

dge_filtered_collapsed <- bartools::collapseReplicates(
  dge_filtered,
  group = "Unique_compound",
  method = "sum", 
  renameCols = TRUE,
  showReps = FALSE)

```

### Visualiation of barcode abundancies

#### Barcode Barplots Abundancies

```{r}
#| label: barcode-abundancies

barcode_barplots <- bartools::plotBarcodeHistogram(
  dge_filtered_collapsed,
  seedColors = 1,
  topN = 10, 
  alphaLowFreq = 0) +
  theme(legend.position = "bottom")

ggsave(barcode_barplots, 
       filename = paste0("./figures/barcode_barplots/top_barcode_", today_date, ".pdf"), 
       dpi = 100, width = 22, height = 12)

```


#### PCAs

- [Re-render using dynamic, and/or annotated PCAs]{fg="red"}

```{r}
#| label: PCA-replicates
pca_plot_replicates <- bartools::plotBarcodePCA(
  dge_filtered_collapsed, 
  groups = c("Compound"), 
  ntop = 500,
  pcs = c(1, 2)) +
  theme(legend.position = "bottom")

ggsave(pca_plot_replicates, 
       filename = paste0("./figures/PCAs/pca_collapsed_replicates_", today_date, ".pdf"), 
       dpi = 300, width = 14, height = 14)
  
```



## Preprocessing barcode counts{#sec-batch-processing}

### **Background Noise Removal**

[Eliminate barcodes for which the combined counts of the 4 controls per barcode are below a given threshold, here `5`.]{fg="blue"} 

```{r}
#| label: background-filtering-and-sample-merging
#| lst-label: lst-background-filtering
#| lst-cap: Remove background noise.

thresh_background <- 4


## filename <- grep( "exp200921", barcode_files, value = TRUE)[2]
barcode_counts_aggregated <- purrr::map(barcode_files, function(filename) {
  barcode_counts <- readr::read_csv(filename)
  experience_name <- filename |> basename() |> tools::file_path_sans_ext()
  
  ## 1) explicitly change replicates name to enable 1-1 mapping ----
  if (experience_name=="exp200921_dose response osim") {
    barcode_counts <- barcode_counts |> 
      dplyr::rename_with(
        .fn = ~ gsub("exp200921_", "exp200921_dose_response_", .x),
        .cols = starts_with("Contro"))
  }
  replicates_names <- setdiff(colnames(barcode_counts), "barcode_id")
  
  ## 2) Remove lowly expressed barcodes ----
  control_index <- pheno_data |> 
    dplyr::filter(Batch_ID==experience_name & 
                    Compound=="Control" &
                    Replicates_ID %in% replicates_names) |> 
    dplyr::pull(Replicates_ID)
  signicant_barcodes_index <- which(rowSums(barcode_counts[, control_index]) > thresh_background)
  filtered_barcode_counts <- barcode_counts[signicant_barcodes_index,]
  
  message(paste("\n\nWe are considering experiment:", experience_name, "with", nrow(filtered_barcode_counts), "barcode IDs kept.\n\n"))
  
  return(filtered_barcode_counts)
}) |> 
  purrr::reduce(~ inner_join(.x, .y, by = "barcode_id"))

## Deal with specific duplicated colnames, resulting from control duplicates
## barcode_counts_aggregated <- barcode_counts_aggregated |>
##   dplyr::select(!ends_with(".y")) |> 
##   dplyr::rename_with(.fn = ~ gsub("\\.x$", "", .x),
##                      .cols = dplyr::ends_with(".x"))

## 3) keep only replicates present in pheno_data
barcode_counts_aggregated <- barcode_counts_aggregated |> 
  select(all_of(c("barcode_id", pheno_data$Replicates_ID)))
```

- After filtering for background noise, and merging all experiences based on shared barcode IDs, `{r} nrow(barcode_counts_aggregated)` unique barcode IDs are kept, for `{r} nrow(pheno_data)` samples, see @lst-background-filtering for details.

- [Density plot of controls + justify why + check absence of outliers, to evaluate the relevance of this threshold, `HTSFilter`, comparison with existing filtering approaches.]{fg="red"}

### **Normalisation**

-   [Normalize barcodes so that the total number of counts per sample is equal to `100,000`]{fg="blue"}. This operation is performed in @lst-cpm-normalisation.

```{r}
#| label: cpm-normalisation
#| lst-label: lst-cpm-normalisation
#| lst-cap: Normalise by $100000$.

## 1) normalise by total number of counts ----
barcode_counts_normalised <- barcode_counts_aggregated |> 
  mutate(across(
    .cols = where(is.numeric),                     
    .fns = ~ (.x / sum(.x)) * 1e5))

```

-   [Close to two existing normalisation methods: **Counts Per Million (CPM)** which additionally scales raw counts by total library size and multiplies by $1,000,000$ and **Total Count Scaling (TCS)**: Scales raw counts by the total number of reads (or mapped reads) in each sample, then multiplies by a fixed number (e.g., 100,000). Would compare other normalisation approaches + ignore biological or technical biases + generate MA plots for verifying the mean-variance correction trend + not suitable for DEGs analyses. Apply concatenation phase of all samples before normalising. [Preprocessing and normalisation functions for transcriptomics: a general overview](https://www.linkedin.com/posts/%F0%9F%8E%AF-ming-tommy-tang-40650014_rna-seq-normalization-what-you-need-to-activity-7313919533780516864-6jFm)]{fg="red"}

### Prepare `SummarizedExperiment` objects for normalised data

- Higher level of granularity in @lst-SummarizedExperiment-replicates:

```{r}
#| label: SummarizedExperiment-replicates
#| lst-label: lst-SummarizedExperiment-replicates
#| lst-cap: Simply compute the Pearson correlation score at the replicate level, and save the output as a `SummarizedExperiment`.

## 2) prepare SummarizedExperiment inputs ----
## Barcode counts at replicate level
barcode_normalised_replicates_mat <- barcode_counts_normalised |> 
                  tibble::column_to_rownames("barcode_id") |> 
                  as.matrix()

## Sample metadata
pheno_data_replicates <- pheno_data |> 
  tibble::column_to_rownames("Replicates_ID") 

## Feature metadata
barcode_metadata <- tibble::tibble(barcode_id = barcode_counts_normalised$barcode_id)
row.names(barcode_metadata) <- barcode_metadata$barcode_id

## 3) Buid and Save SummarizedExperiment
se_replicates <- SummarizedExperiment::SummarizedExperiment(
  assays = list(counts = barcode_normalised_replicates_mat),
  rowData = barcode_metadata,
  colData = pheno_data_replicates)

``` 

- Medium level of granularity in @lst-SummarizedExperiment-compound-per-batch, averaging over replicates:

```{r}
#| label: SummarizedExperiment-compound-per-batch
#| lst-label: lst-SummarizedExperiment-compound-per-batch
#| lst-cap: Simply compute the Pearson correlation score at the Compound per Batch level.

barcode_counts_long <- barcode_counts_normalised |> 
  tidyr::pivot_longer(-barcode_id, 
                      names_to = "Replicates_ID",
                      values_to = "Barcode_Counts") |> 
  dplyr::inner_join(pheno_data, by="Replicates_ID")

barcode_counts_wider_compound_batch <- barcode_counts_long |> 
  tidyr::pivot_wider(id_cols = c(barcode_id), 
                     names_from = c(Batch_ID, Compound, Concentrations_ID, Duration_ID),
                     names_sep = ":",
                     values_from = Barcode_Counts, 
                     values_fn=mean)

pheno_compound_batch <- tibble::tibble(original =setdiff(colnames(barcode_counts_wider_compound_batch),"barcode_id")) |>
  mutate(Batch_ID = stringr::str_split_i(original, ":", 1),
         Compound = stringr::str_split_i(original, ":", 2), 
         Concentrations_ID = stringr::str_split_i(original, ":", 3), 
         Duration_ID = stringr::str_split_i(original, ":", 4)) |>
  inner_join(pheno_data |> select(Batch_ID, Pathway, MoA, Compound, 
                                  Concentrations, Concentrations_ID, Duration, Duration_ID), 
             by = c("Batch_ID", "Compound", "Concentrations_ID", "Duration_ID")) |> 
  dplyr::distinct() |> 
  dplyr::select(-Concentrations_ID, -Duration_ID) |> 
  tibble::column_to_rownames("original") 

se_compound_batch <- SummarizedExperiment::SummarizedExperiment(
  assays = list(counts = barcode_counts_wider_compound_batch |> 
                  tibble::column_to_rownames("barcode_id") |> 
                  as.matrix()),
  rowData = barcode_metadata,
  colData = pheno_compound_batch)

```

- Low level of granularity in @lst-SummarizedExperiment-compound, with one CC per compound:

```{r}
#| label: SummarizedExperiment-compound
#| lst-label: lst-SummarizedExperiment-compound
#| lst-cap: Compute the Pearson correlation score, after averaging the barcode counts per compound.

barcode_counts_wider_by_compound <- barcode_counts_long |> 
  tidyr::pivot_wider(id_cols = c(barcode_id), 
                     names_from = c(Compound),
                     values_from = Barcode_Counts, 
                     values_fn=mean)

pheno_compound <- tibble::tibble(Compound = setdiff(colnames(barcode_counts_wider_by_compound), "barcode_id")) |>
  inner_join(pheno_data |> select(Pathway, MoA, Compound), 
             by = c("Compound")) |> 
  dplyr::distinct() |> 
  tibble::column_to_rownames("Compound") 

se_compound <- SummarizedExperiment::SummarizedExperiment(
  assays = list(counts = barcode_counts_wider_by_compound |> 
                  tibble::column_to_rownames("barcode_id") |> 
                  as.matrix()),
  rowData = barcode_metadata,
  colData = pheno_compound)

```

```{r}
#| label: save-SummarizedExperiment-counts

saveRDS(se_replicates, file = paste0("./results/compounds/se_normalised_per_replicate_",
                          today_date, ".rds"))
saveRDS(se_compound_batch, file = paste0("./results/compounds/se_normalised_per_compound_by_batch_",
                          today_date, ".rds"))
saveRDS(se_compound, file = paste0("./results/compounds/se_normalised_per_compound_",
                          today_date, ".rds"))
```


## **Differential analyses** and Binarisation

1. [Calculate mean of the 4 controls, followed by **Differential Represented Barcode Analysis**: binarise each replicate, assigning a 1 if Fold change is above 3 with respect to Mean value, and 0 otherwise]{fg="blue"} 

```{r}
#| label: differential-barcode-analysis
#| lst-label: lst-differential-barcode-analysis
#| lst-cap: Compute the averaged value for control replicates, then binarise for each compound. A `1` denoting a significant positive enrichment for a given `barcode_id`.

## Step 1: Compute control means per barcode_id and Batch ----
threshold_FC <- 3
control_means <- barcode_counts_long |>
  filter(Compound == "Control") |>
  group_by(Batch_ID, barcode_id) |>
  summarise(Control_Mean = mean(Barcode_Counts), .groups = "drop")

## Step 2: Join control mean to full dataset ----
barcode_discretised_replicates <- barcode_counts_long |>
  left_join(control_means, 
            by = c("Batch_ID","barcode_id"))

## Step 3: Compute Fold Change and discretise ----
barcode_discretised_replicates <- barcode_discretised_replicates |>
  filter(Compound != "Control") |>
  mutate(Diff = Barcode_Counts - Control_Mean,
    Barcode_Counts = if_else(Diff > threshold_FC, 1, 0)) |>
  ## Final cleanup 
  select(-Diff, -Control_Mean)  |> 
  dplyr::mutate(Barcode_Counts = as.logical(Barcode_Counts))

```

[Batch effect correction for integrating across batches? // As Vera emphasised it out, why keeping only positive values? Negative are also interesting. Why not pairing $p$-values and fold-change (considering indeed really small sample sizes)? // All these operations can be performed with one run, using `lm`, and a model as such, $\text{Expr} \sim 0 + \text{Gene} + \text{Batch} + \text{Drug}$, with a `contr.treatment` design matrix // Perform **sensitivity analyses** to evaluate the impact of threshold criteriaon for binarisation on downstream analyses. [^1]]{fg="red"}.

[^1]: Test the **Helmert contrast** to evaluate *compound dose response*, or *time-course replicates*. Also For repeated measures across time, see [One Way repeated measure ANOVA in R](https://www.r-bloggers.com/2025/02/one-way-repeated-measure-anova-in-r/)

### `SummarizedExperiment` of binarised markers

- `SummarizedExperiment` at the replicates level (controls being discarded)

```{r}
#| label: replicates-discretised
## Step 4: Save as a SummarizedExperiment ----
barcode_discretised_replicates_mat <- barcode_discretised_replicates |> 
  tidyr::pivot_wider(id_cols = barcode_id, names_from = Replicates_ID, values_from = Barcode_Counts)

pheno_replicates_discretised <- pheno_data |> 
  dplyr::filter(Replicates_ID %in% barcode_discretised_replicates$Replicates_ID) |> 
  tibble::column_to_rownames("Replicates_ID") 

se_discretised_replicates <- SummarizedExperiment::SummarizedExperiment(
  assays = list(binarised = barcode_discretised_replicates_mat |> 
                  tibble::column_to_rownames("barcode_id") |> 
                  as.matrix()),
  rowData = barcode_metadata,
  colData = pheno_replicates_discretised)

saveRDS(se_discretised_replicates,
        file = paste0("./results/compounds/se_discretised_per_replicate_",
                      today_date, ".rds"))
```


- [Logical `AND` over replicates: drug by batch (and concentration and time).]{fg="blue"} 

```{r}
#| label: compound-by-batch-discretised
#| lst-label: lst-compound-by-batch-discretised
#| lst-cap: "Average the replicates, using a `all` operator."

## 2) discretised correlation at the compound by batch level (averaging over replicates), with an all function
barcode_discretised_compound_batch <- barcode_discretised_replicates |> 
   tidyr::pivot_wider(id_cols = c(barcode_id), 
                     names_from = c(Batch_ID, Compound, Concentrations_ID, Duration_ID),
                     names_sep = ":",
                     values_from = Barcode_Counts, 
                     values_fn=all)

pheno_discretised_compound_batch <- pheno_compound_batch[setdiff(colnames(barcode_discretised_compound_batch), "barcode_id"), ]

se_compound_batch_discretised <- SummarizedExperiment::SummarizedExperiment(
  assays = list(discretised = barcode_discretised_compound_batch |> 
                  tibble::column_to_rownames("barcode_id") |> 
                  as.matrix()),
  rowData = barcode_metadata,
  colData = pheno_discretised_compound_batch)

saveRDS(se_compound_batch_discretised,
        file = paste0("./results/compounds/se_discretised_per_compound_by_batch_",
                      today_date, ".rds"))

```

- [Average over compounds.]{fg="blue"} 

```{r}
#| label: compound-discretised
#| lst-label: lst-compound-discretised
#| lst-cap: "Aggregate at the compound level, assigning a 1 if barcode cell lines were found positiveliy enriched in all compounds."
## 2) discretised correlation at the compound by batch level (averaging over replicates), with an all function
barcode_discretised_compound <- barcode_discretised_replicates |> 
   tidyr::pivot_wider(id_cols = c(barcode_id), 
                     names_from = c(Compound),
                     names_sep = ":",
                     values_from = Barcode_Counts, 
                     values_fn=all)

pheno_discretised_compound<- pheno_compound[setdiff(colnames(barcode_discretised_compound), "barcode_id"), ]

se_compound_discretised <- SummarizedExperiment::SummarizedExperiment(
  assays = list(discretised = barcode_discretised_compound |> 
                  tibble::column_to_rownames("barcode_id") |> 
                  as.matrix()),
  rowData = barcode_metadata,
  colData = pheno_discretised_compound)

saveRDS(se_compound_discretised,
        file = paste0("./results/compounds/se_discretised_per_compound_",
                      today_date, ".rds"))

```

