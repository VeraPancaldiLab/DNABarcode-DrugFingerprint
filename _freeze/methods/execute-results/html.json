{
  "hash": "3a64fab15989c305920335541b45bdf0",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Methods: normalise, identify DRBs and save as `SummarizedExperiment` objects\"\n---\n\n\n\n\n\n\n## Reproducibility\n\nI list below the R packages required to reproduce the analyses.\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n## data wrangling\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(stringr)\nlibrary(readr)\nlibrary(readxl)\nlibrary(openxlsx)\nlibrary(purrr)\n\n## reporting\nlibrary(flextable)\n\n# automated package linting\nlibrary(xml2)\nlibrary(downlit)\n\n## auxiliary functions\nsource(\"R/utils.R\")\ntoday_date <- \"2025-04-28\"\n## today_date <- format(Sys.Date(), \"%Y-%m-%d\")\n\n## set the seed, for fixing generation of ComplexHeatmaps (dendogram clustering)\nset.seed(20)\n```\n:::\n\n\n\n\n\n\n\n## Preprocessing barcode counts{#sec-batch-processing}\n\n**Code colour**: [Luca's protocol]{fg=\"blue\"}, and [Bastien's comments and perspectives]{fg=\"red\"}\n\n### **Background Noise Removal** and `SummarizedExperiment` stantardised storage\n\n[Eliminate barcodes for which the combined counts of the 4 controls per barcode are below a given threshold, here `5`.]{fg=\"blue\"} \n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{#lst-background-filtering .r .cell-code  lst-cap=\"Remove background noise.\"}\nbarcode_files <- list.files(\"./data/barcode-counts/\",\n                            pattern = \"exp.*\\\\.csv\",\n                            full.names = TRUE)\nthresh_background <- 4\n## ./data/pheno_data_metadata_2025-04-18.csv\npheno_data <- readr::read_csv(paste0(\"./data/pheno_data_metadata_\",\n                                     today_date, \".csv\"))\n\n## filename <- grep( \"exp200921\", barcode_files, value = TRUE)[2]\nbarcode_counts_aggregated <- purrr::map(barcode_files, function(filename) {\n  barcode_counts <- readr::read_csv(filename)\n  experience_name <- filename |> basename() |> tools::file_path_sans_ext()\n  \n  ## 1) explicitly change replicates name to enable 1-1 mapping ----\n  if (experience_name==\"exp200921_dose response osim\") {\n    barcode_counts <- barcode_counts |> \n      dplyr::rename_with(\n        .fn = ~ gsub(\"exp200921_\", \"exp200921_dose_response_\", .x),\n        .cols = starts_with(\"Contro\"))\n  }\n  replicates_names <- setdiff(colnames(barcode_counts), \"barcode_id\")\n  \n  ## 2) Remove lowly expressed barcodes ----\n  control_index <- pheno_data |> \n    dplyr::filter(Batch_ID==experience_name & \n                    Compound==\"Control\" &\n                    Replicates_ID %in% replicates_names) |> \n    dplyr::pull(Replicates_ID)\n  signicant_barcodes_index <- which(rowSums(barcode_counts[, control_index]) > thresh_background)\n  filtered_barcode_counts <- barcode_counts[signicant_barcodes_index,]\n  \n  message(paste(\"\\n\\nWe are considering experiment:\", experience_name, \"with\", nrow(filtered_barcode_counts), \"barcode IDs kept.\\n\\n\"))\n  \n  return(filtered_barcode_counts)\n}) |> \n  purrr::reduce(~ inner_join(.x, .y, by = \"barcode_id\"))\n\n## Deal with specific duplicated colnames, resulting from control duplicates\n## barcode_counts_aggregated <- barcode_counts_aggregated |>\n##   dplyr::select(!ends_with(\".y\")) |> \n##   dplyr::rename_with(.fn = ~ gsub(\"\\\\.x$\", \"\", .x),\n##                      .cols = dplyr::ends_with(\".x\"))\n\n## 3) keep only replicates present in pheno_data\nbarcode_counts_aggregated <- barcode_counts_aggregated |> \n  select(all_of(c(\"barcode_id\", pheno_data$Replicates_ID)))\n```\n:::\n\n\n\n\n\n\n- After filtering for background noise, and merging all experiences based on shared barcode IDs, 4629 unique barcode IDs are kept, for 532 samples, see @lst-background-filtering for details.\n\n- [Density plot of controls + justify why + check absence of outliers, to evaluate the relevance of this threshold, `HTSFilter`, comparison with existing filtering approaches.]{fg=\"red\"}\n\n### **Normalisation**\n\n-   [Normalize barcodes so that the total number of counts per sample is equal to `100,000`]{fg=\"blue\"}. This operation is performed in @lst-cpm-normalisation.\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{#lst-cpm-normalisation .r .cell-code  lst-cap=\"Normalise by $100000$.\"}\n## 1) normalise by total number of counts ----\nbarcode_counts_normalised <- barcode_counts_aggregated |> \n  mutate(across(\n    .cols = where(is.numeric),                     \n    .fns = ~ (.x / sum(.x)) * 1e5))\n\n```\n:::\n\n\n\n\n\n\n-   [Close to two existing normalisation methods: **Counts Per Million (CPM)** which additionally scales raw counts by total library size and multiplies by $1,000,000$ and **Total Count Scaling (TCS)**: Scales raw counts by the total number of reads (or mapped reads) in each sample, then multiplies by a fixed number (e.g., 100,000). Would compare other normalisation approaches + ignore biological or technical biases + generate MA plots for verifying the mean-variance correction trend + not suitable for DEGs analyses. Apply concatenation phase of all samples before normalising. [Preprocessing and normalisation functions for transcriptomics: a general overview](https://www.linkedin.com/posts/%F0%9F%8E%AF-ming-tommy-tang-40650014_rna-seq-normalization-what-you-need-to-activity-7313919533780516864-6jFm)]{fg=\"red\"}\n\n### Prepare `SummarizedExperiment` objects for normalised data\n\n- Higher level of granularity in @lst-SummarizedExperiment-replicates:\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{#lst-SummarizedExperiment-replicates .r .cell-code  lst-cap=\"Simply compute the Pearson correlation score at the replicate level, and save the output as a `SummarizedExperiment`.\"}\n## 2) prepare SummarizedExperiment inputs ----\n## Barcode counts at replicate level\nbarcode_normalised_replicates_mat <- barcode_counts_normalised |> \n                  tibble::column_to_rownames(\"barcode_id\") |> \n                  as.matrix()\n\n## Sample metadata\npheno_data_replicates <- pheno_data |> \n  tibble::column_to_rownames(\"Replicates_ID\") \n\n## Feature metadata\nbarcode_metadata <- tibble::tibble(barcode_id = barcode_counts_normalised$barcode_id)\nrow.names(barcode_metadata) <- barcode_metadata$barcode_id\n\n## 3) Buid and Save SummarizedExperiment\nse_replicates <- SummarizedExperiment::SummarizedExperiment(\n  assays = list(counts = barcode_normalised_replicates_mat),\n  rowData = barcode_metadata,\n  colData = pheno_data_replicates)\n\n```\n:::\n\n\n\n\n\n\n- Medium level of granularity in @lst-SummarizedExperiment-compound-per-batch, averaging over replicates:\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{#lst-SummarizedExperiment-compound-per-batch .r .cell-code  lst-cap=\"Simply compute the Pearson correlation score at the Compound per Batch level.\"}\nbarcode_counts_long <- barcode_counts_normalised |> \n  tidyr::pivot_longer(-barcode_id, \n                      names_to = \"Replicates_ID\",\n                      values_to = \"Barcode_Counts\") |> \n  dplyr::inner_join(pheno_data, by=\"Replicates_ID\")\n\nbarcode_counts_wider_compound_batch <- barcode_counts_long |> \n  tidyr::pivot_wider(id_cols = c(barcode_id), \n                     names_from = c(Batch_ID, Compound, Concentrations_ID, Duration_ID),\n                     names_sep = \":\",\n                     values_from = Barcode_Counts, \n                     values_fn=mean)\n\npheno_compound_batch <- tibble::tibble(original =setdiff(colnames(barcode_counts_wider_compound_batch),\"barcode_id\")) |>\n  mutate(Batch_ID = stringr::str_split_i(original, \":\", 1),\n         Compound = stringr::str_split_i(original, \":\", 2), \n         Concentrations_ID = stringr::str_split_i(original, \":\", 3), \n         Duration_ID = stringr::str_split_i(original, \":\", 4)) |>\n  inner_join(pheno_data |> select(Batch_ID, Pathway, MoA, Compound, \n                                  Concentrations, Concentrations_ID, Duration, Duration_ID), \n             by = c(\"Batch_ID\", \"Compound\", \"Concentrations_ID\", \"Duration_ID\")) |> \n  dplyr::distinct() |> \n  dplyr::select(-Concentrations_ID, -Duration_ID) |> \n  tibble::column_to_rownames(\"original\") \n\nse_compound_batch <- SummarizedExperiment::SummarizedExperiment(\n  assays = list(counts = barcode_counts_wider_compound_batch |> \n                  tibble::column_to_rownames(\"barcode_id\") |> \n                  as.matrix()),\n  rowData = barcode_metadata,\n  colData = pheno_compound_batch)\n\n```\n:::\n\n\n\n\n\n\n- Low level of granularity in @lst-SummarizedExperiment-compound, with one CC per compound:\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{#lst-SummarizedExperiment-compound .r .cell-code  lst-cap=\"Compute the Pearson correlation score, after averaging the barcode counts per compound.\"}\nbarcode_counts_wider_by_compound <- barcode_counts_long |> \n  tidyr::pivot_wider(id_cols = c(barcode_id), \n                     names_from = c(Compound),\n                     values_from = Barcode_Counts, \n                     values_fn=mean)\n\npheno_compound <- tibble::tibble(Compound = setdiff(colnames(barcode_counts_wider_by_compound), \"barcode_id\")) |>\n  inner_join(pheno_data |> select(Pathway, MoA, Compound), \n             by = c(\"Compound\")) |> \n  dplyr::distinct() |> \n  tibble::column_to_rownames(\"Compound\") \n\nse_compound <- SummarizedExperiment::SummarizedExperiment(\n  assays = list(counts = barcode_counts_wider_by_compound |> \n                  tibble::column_to_rownames(\"barcode_id\") |> \n                  as.matrix()),\n  rowData = barcode_metadata,\n  colData = pheno_compound)\n\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsaveRDS(se_replicates, file = paste0(\"./results/compounds/se_normalised_per_replicate_\",\n                          today_date, \".rds\"))\nsaveRDS(se_compound_batch, file = paste0(\"./results/compounds/se_normalised_per_compound_by_batch_\",\n                          today_date, \".rds\"))\nsaveRDS(se_compound, file = paste0(\"./results/compounds/se_normalised_per_compound_\",\n                          today_date, \".rds\"))\n```\n:::\n\n\n\n\n\n\n\n## **Differential analyses** and Binarisation\n\n1. [Calculate mean of the 4 controls, followed by **Differential Represented Barcode Analysis**: binarise each replicate, assigning a 1 if Fold change is above 3 with respect to Mean value, and 0 otherwise]{fg=\"blue\"} \n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{#lst-differential-barcode-analysis .r .cell-code  lst-cap=\"Compute the averaged value for control replicates, then binarise for each compound. A `1` denoting a significant positive enrichment for a given `barcode_id`.\"}\n## Step 1: Compute control means per barcode_id and Batch ----\nthreshold_FC <- 3\ncontrol_means <- barcode_counts_long |>\n  filter(Compound == \"Control\") |>\n  group_by(Batch_ID, barcode_id) |>\n  summarise(Control_Mean = mean(Barcode_Counts), .groups = \"drop\")\n\n## Step 2: Join control mean to full dataset ----\nbarcode_discretised_replicates <- barcode_counts_long |>\n  left_join(control_means, \n            by = c(\"Batch_ID\",\"barcode_id\"))\n\n## Step 3: Compute Fold Change and discretise ----\nbarcode_discretised_replicates <- barcode_discretised_replicates |>\n  filter(Compound != \"Control\") |>\n  mutate(Diff = Barcode_Counts - Control_Mean,\n    Barcode_Counts = if_else(Diff > threshold_FC, 1, 0)) |>\n  ## Final cleanup \n  select(-Diff, -Control_Mean)  |> \n  dplyr::mutate(Barcode_Counts = as.logical(Barcode_Counts))\n\n```\n:::\n\n\n\n\n\n\n[Batch effect correction for integrating across batches? // As Vera emphasised it out, why keeping only positive values? Negative are also interesting. Why not pairing $p$-values and fold-change (considering indeed really small sample sizes)? // All these operations can be performed with one run, using `lm`, and a model as such, $\\text{Expr} \\sim 0 + \\text{Gene} + \\text{Batch} + \\text{Drug}$, with a `contr.treatment` design matrix // Perform **sensitivity analyses** to evaluate the impact of threshold criteriaon for binarisation on downstream analyses. [^1]]{fg=\"red\"}.\n\n[^1]: Test the **Helmert contrast** to evaluate *compound dose response*, or *time-course replicates*. Also For repeated measures across time, see [One Way repeated measure ANOVA in R](https://www.r-bloggers.com/2025/02/one-way-repeated-measure-anova-in-r/)\n\n### `SummarizedExperiment` of binarised markers\n\n- `SummarizedExperiment` at the replicates level (controls being discarded)\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n## Step 4: Save as a SummarizedExperiment ----\nbarcode_discretised_replicates_mat <- barcode_discretised_replicates |> \n  tidyr::pivot_wider(id_cols = barcode_id, names_from = Replicates_ID, values_from = Barcode_Counts)\n\npheno_replicates_discretised <- pheno_data |> \n  dplyr::filter(Replicates_ID %in% barcode_discretised_replicates$Replicates_ID) |> \n  tibble::column_to_rownames(\"Replicates_ID\") \n\nse_discretised_replicates <- SummarizedExperiment::SummarizedExperiment(\n  assays = list(binarised = barcode_discretised_replicates_mat |> \n                  tibble::column_to_rownames(\"barcode_id\") |> \n                  as.matrix()),\n  rowData = barcode_metadata,\n  colData = pheno_replicates_discretised)\n\nsaveRDS(se_discretised_replicates,\n        file = paste0(\"./results/compounds/se_discretised_per_replicate_\",\n                      today_date, \".rds\"))\n```\n:::\n\n\n\n\n\n\n\n- [Logical `AND` over replicates: drug by batch (and concentration and time).]{fg=\"blue\"} \n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{#lst-compound-by-batch-discretised .r .cell-code  lst-cap=\"Average the replicates, using a `all` operator.\"}\n## 2) discretised correlation at the compound by batch level (averaging over replicates), with an all function\nbarcode_discretised_compound_batch <- barcode_discretised_replicates |> \n   tidyr::pivot_wider(id_cols = c(barcode_id), \n                     names_from = c(Batch_ID, Compound, Concentrations_ID, Duration_ID),\n                     names_sep = \":\",\n                     values_from = Barcode_Counts, \n                     values_fn=all)\n\npheno_discretised_compound_batch <- pheno_compound_batch[setdiff(colnames(barcode_discretised_compound_batch), \"barcode_id\"), ]\n\nse_compound_batch_discretised <- SummarizedExperiment::SummarizedExperiment(\n  assays = list(discretised = barcode_discretised_compound_batch |> \n                  tibble::column_to_rownames(\"barcode_id\") |> \n                  as.matrix()),\n  rowData = barcode_metadata,\n  colData = pheno_discretised_compound_batch)\n\nsaveRDS(se_compound_batch_discretised,\n        file = paste0(\"./results/compounds/se_discretised_per_compound_by_batch_\",\n                      today_date, \".rds\"))\n\n```\n:::\n\n\n\n\n\n\n- [Average over compounds.]{fg=\"blue\"} \n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{#lst-compound-discretised .r .cell-code  lst-cap=\"Aggregate at the compound level, assigning a 1 if barcode cell lines were found positiveliy enriched in all compounds.\"}\n## 2) discretised correlation at the compound by batch level (averaging over replicates), with an all function\nbarcode_discretised_compound <- barcode_discretised_replicates |> \n   tidyr::pivot_wider(id_cols = c(barcode_id), \n                     names_from = c(Compound),\n                     names_sep = \":\",\n                     values_from = Barcode_Counts, \n                     values_fn=all)\n\npheno_discretised_compound<- pheno_compound[setdiff(colnames(barcode_discretised_compound), \"barcode_id\"), ]\n\nse_compound_discretised <- SummarizedExperiment::SummarizedExperiment(\n  assays = list(discretised = barcode_discretised_compound |> \n                  tibble::column_to_rownames(\"barcode_id\") |> \n                  as.matrix()),\n  rowData = barcode_metadata,\n  colData = pheno_discretised_compound)\n\nsaveRDS(se_compound_discretised,\n        file = paste0(\"./results/compounds/se_discretised_per_compound_\",\n                      today_date, \".rds\"))\n\n```\n:::\n",
    "supporting": [
      "methods_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}