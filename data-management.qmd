---
title: "Data management: metadata correction and cleansing"
---

## Reproducibility

I list below the R packages required to reproduce the analyses.

```{r}
#| label: setup

## data wrangling
library(dplyr)
library(tidyr)
library(stringr)
library(readr)
library(readxl)
library(purrr)

## reporting
library(flextable)

## auxiliary functions
source("R/utils.R")
today_date <- "2025-06-13"
# today_date <- format(Sys.Date(), "%Y-%m-%d")

```
## Barcode counts cleaning {#sec-select-exp}

- [Original Google Drive repository](https://drive.google.com/drive/folders/1pMSX4M4kHcDGxcsCzsMYHHM6VRvBHHUO).

- Below, we convert each `.TABULAR` file to its recommended `.tsv` file extension, and rename unequivocally the first `colname` into `barcode_id`:
    
```{r}
#| label: format-barcode-tsv
#| echo: true
#| eval: false
barcode_files <- list.files("./data/barcode-counts/", 
                               pattern = "exp.*\\.tabular", 
                               full.names = TRUE)

## change format + barcode name
barcode_matrices <- lapply(barcode_files, function(old_filename) {
  expression_matrix <- readxl::read_tsv(old_filename) |> 
    rename(barcode_id = 1)
  
  new_filename <- old_filename |> basename() |> tools::file_path_sans_ext()
  
  readr::write_tsv(expression_matrix, 
                   file = file.path("data", "barcode-counts", paste0(new_filename, ".tsv")))
  unlink(old_filename, force = TRUE)
  
})
```


- [I rename the first colname of each expression file as `barcode_id`, storing unequivocal tag.]{fg="red"}
- List of changes applied for easier mapping between replicates' barcode profiles and samples' metadata:

  - `exp130921`, switch from `Osimer1_001g_exp130921_run101121_28` to `Osimer1_001m_exp130921_run101121_28`, from `001g` to `001m` (*in-vivo* context), and switch from `Azacyt1_1,5u_exp130921_run290921_40` to `Azacyt1_1.50u_exp130921_run290921_40`, `1,5u` to `1.50u`^[*In-vivo* = cells injected in living mice, `control` versus `osermintinimb`.].
  - `exp200921`: switch from `Bafilo1_1,2n_exp200921_run111021_45` to `Bafilo1_1.20n_exp200921_run111021_45`, `1,2n` to `1.20n`. In addition, [the 4 control replicates of *dose-response* batch `exp200921_dose_response` are shared with standard experiment `exp200921.csv`.]{fg="red"}
  - `exp151121`: switch from `Mitomy1_002x_exp151121_run071221_37` to `Mitomy1_0.02u_exp151121_run071221_37`, `002x` to `0.02u`.
  - `exp070222`: switch from `Tunica1_0,5x_exp070222_run010322_05` to `Tunica1_0.50u_exp070222_run010322_05`, `0,5x` to `0.50u`.
  - `exp070222t25`: more comprehensive, so we keep the oldest one (no replicate `cDNA` missing). From `cDNA1_000u_exp281022_run141222_01` to `Contro1_000u_exp281022_run141222_01`! [What does `cDNA` refer to as?]{fg="red"}.
  - `exp281022t25`: one control and 3 Drug Compounds were sampled in **T25 flasks**. `P42` and `P43` are used for evaluating *barcode drift*, a technical artefact in relation with depth sequencing. [Most of the replicates lack of significant effect due to insufficient dose]{fg="red"}.
- `exp281022gamme` refers to the time course experiment.

We report in @tbl-overview-barcode-counts a summary of the barcode counts (File location, `batch_id`, and dimensions).

```{r}
#| label: tbl-overview-barcode-counts
#| tbl-cap: "Main Batch features."

barcode_files <- list.files("./data/barcode-counts/",
                            pattern = "exp.*\\.tsv",
                            full.names = TRUE)
barcode_summaries <- purrr::map(barcode_files, function(filename) {
  barcode_counts <- readr::read_tsv(filename, show_col_types = FALSE)
  experience_summary <- tibble::tibble(Filename = basename(filename),
                                       `Num Barcode IDs` = nrow(barcode_counts),
                                       `Num Replicates` = ncol(barcode_counts) - 1)
  return(experience_summary)
}) |>
  purrr::list_rbind()

barcode_summaries <- barcode_summaries |>
  dplyr::inner_join(readxl::read_excel("data/Table of compounds_whole_2025-06-13.xlsx",
    sheet = "Batch Mapping"),
    by = "Filename") |>
  dplyr::relocate(Batch_ID, .after = Filename) |>
  dplyr::relocate(`Num Barcode IDs`, `Num Replicates`, .after = `Run date`)

flextable::flextable(barcode_summaries) |>
  bold(part = "header") |> 
  flextable::merge_v(j = c("Filename", "Batch_ID", "General Comments Per Batch"),
                      part = "body")

openxlsx::write.xlsx(x = barcode_summaries, asTable = TRUE,
                     file = paste0("./data/barcode_counts_summaries_", today_date, ".xlsx"))
```

From @tbl-overview-barcode-counts: 

- **Number of barcode counts profiles**: `{r} length(barcode_files)`
- **Number of batches**:  `{r} length(unique(barcode_summaries$Date))`, retrieved on number of dates.
- **Number of runs**: `{r} length(unique(barcode_summaries$`Run date`))`, based on the total number of Barcode sequencing Runs. 
- **Number of experiments**: `{r} length(unique(barcode_summaries$Batch_ID))`, based on Batch IDs.
- **Technical covariates**: `{r} nrow(barcode_summaries)`. Is computed as the *Cartesian product* of batches per run, both Date of experiment and sequencing could impact the output.

## `DrugSimDB` to map each compound a Pathway and MoA {#sec-DrugSimDB}

- Map `DrugBank-ID` to their raw generic drug name, with [`drug_id_mapping.tsv`](https://github.com/iit-Demokritos/drug_id_mapping/blob/main/drug-mappings.tsv). 

```{r}
#| label: map-drugbankID-to-generic-name
# check after Samples_ID, to highlight duplicates

compound_metadata <- readr::read_csv(paste0("./data/replicates_barcode_metadata_comprehensive_",
                                     today_date, ".csv"), 
                              show_col_types = FALSE) |> 
  dplyr::filter(!Pathway %in% c("Control", "Drug combinations", "Novel compound", "Control - time zero")) |> 
  dplyr::distinct(Pathway, Compound)

utils::download.file(url = "https://raw.githubusercontent.com/iit-Demokritos/drug_id_mapping/refs/heads/main/drug-mappings.tsv", 
                     destfile = "./data/drugbank/drug-mappings.tsv")
drug_mappings <- readr::read_tsv("./data/drugbank/drug-mappings.tsv")

compound_metadata_mapped <- compound_metadata |> 
  fuzzyjoin::stringdist_left_join(drug_mappings |> 
                                    dplyr::select(drugbankId, name),
                                  by = c(Compound = "name"),
 # https://www.rdocumentation.org/packages/stringdist/versions/0.9.15/topics/stringdist-metrics, Damerau-Levenshtein distance                             
                                  method = "osa", 
                                  max_dist = 2,
                                  distance_col = "distance") |> 
  dplyr::rename(Generic_Name = name, Compound_Luca = Compound) |> 
  dplyr::relocate(Generic_Name, .after = Compound_Luca)

openxlsx::write.xlsx(compound_metadata_mapped,
                     file = "./data/drugbank/mapped_drugs_barcode.xlsx", 
                     asTable = TRUE)

```


  - **Example**: `DrugBankID: DB12218` to its `generic name: Capivasertib`.

- Retrieve [raw drugbank XML](https://www.synapse.org/Portal/filehandleassociation?associatedObjectId=syn22321343&associatedObjectType=FileEntity&fileHandleId=64023744), to map each generic drug name to its corresponding `DrugBank-ID`. 
  
  1. Create a free account on [`Synapse`](https://www.synapse.org/Profile:3546765/profile), a website dedicated to open-source.
  2. Use [`drugbankR`](https://github.com/girke-lab/drugbankR) package to 1) convert the `xml` file format of `DrugBank` into a tidy dataframe, and 2) use `SQLite` syntax to explore it.
  3. (Alternative): Perform API requests directly on [`DrugBank`](https://go.drugbank.com/drugs), but it requires to log in as an academic, and might be slower than querying a local database. 

### `DrugSimDB` and similarity scores: 

  1. [Update drug-drug similarity measures based on the latest version of `Drugbank`](https://github.com/VafaeeLab/drugSimDB/blob/master/update_databases/ReadMe.md), a tutorial mixing `shell` commands and R scripts. 
  
  2. [Main Similarity scores resulting from running DD steps of `DrugBank`](https://figshare.com/articles/dataset/DrugSimDB/11948904). Similarity scores cover 6 items: `Chemical structure`,`Targets`, `Gene Ontology`, `Cellular component`, `Molecular Function` and `Biological process of induced pathways`.
 

 
```{r}
#| label: download-drugbank
#| echo: true
#| eval: false

library(httr)
library(jsonlite)

# Get InChIKey from PubChem for Levofloxacin (or use webchem)
inchikey <- "GSDSWSVVBLHKDQ-UHFFFAOYSA-N"

# Use UniChem to get DrugBank ID
url <- paste0("https://www.ebi.ac.uk/unichem/rest/inchikey/", inchikey)
res <- fromJSON(url)


url_base <- "https://go.drugbank.com/drugs"
drug_identifier <- "DB00358"
drug_detailled_information <- httr2::request(url_base) |>
  httr2::req_url_path_append(drug_identifier) |>
  httr2::req_perform() |>
  httr2::resp_body_json()

url_base <- paste0("https://go.drugbank.com/drugs", drug_identifier)
res <- jsonlite::fromJSON(url_base)




renv::install("girke-lab/drugbankR")
drugbank_dataframe <- drugbankR::dbxml2df( xmlfile = "data/drugbank/drugbank.xml",
                                           version = "5.1.3") 
```
 


## Phenotype metadata cleaning {#sec-metadata-phenotypes}

Most of the R instructions reported in this section aim at rendering the `Table of compounds` file compliant with the `tidy` format, see @tip-tidyformat. These data-wrangling operations are split in 4 steps:

1. In @lst-process-pheno1, we homogenise `Concentrations`, `Date` and `Duration` to ISO standards, while dealing with erroneous missing values generated by fused Excel cells. 

```{r}
#| label: process-pheno1
#| lst-label: lst-process-pheno1
#| lst-cap: Coerce original Excel file reporting experimental design to tidy format.

pheno_colnames <- c(Old_Pathway = "Pathways", Old_MoA = "...2", 
                    Compound = "Samples", Replicates = "Replicates",
                    Concentrations_Formatted = "Concentrations", Date = "Experiment date",
                    `Run date` = "Run date", Duration_ID = "Duration", 
                    Kept = "Kept", Comments = "Comments")

## prune irrelevant colnames ----

samples_metadata <- readxl::read_xlsx("data/Table of compounds_whole_2025-06-13.xlsx",
                                sheet = "Experimental Design",
                                col_types = c(rep("text", 3), "numeric", 
                                              rep("text", 4), "logical", "text")) |>
  dplyr::rename(dplyr::all_of(pheno_colnames)) |>
  tidyr::fill(Old_Pathway, Old_MoA, .direction = "down") |> 
  tidyr::fill(Compound, .direction = "down") |>
  dplyr::mutate(Old_Pathway = if_else(is.na(Old_Pathway), Old_MoA, Old_Pathway)) 

# integrate new pathway information from Luca ----
updated_MoA_pathway <- readxl::read_xlsx("data/Table of compounds_whole_2025-06-13.xlsx", 
                                                       sheet = "Pathway Mapping")
samples_metadata <- samples_metadata |> 
  dplyr::inner_join(updated_MoA_pathway,
                   by = join_by(Compound)) 

## format concentrations, creating both 'Concentrations_ID' and 'Concentrations' in Moles ----
samples_metadata <- samples_metadata |> 
  dplyr::mutate(Concentrations=if_else(grepl("^(Control|P42|P43)", Compound), "000 uM", Concentrations_Formatted)) |> 
  dplyr::mutate(Concentrations=if_else(Compound == "Osimertinb+sorafenib", "015 uM", Concentrations)) |>
  tidyr::separate_wider_delim(Concentrations, delim = " ", names = c("Concentrations Value", "Unit"), cols_remove = FALSE) |>
  dplyr::mutate(Unit = case_when(
    Unit %in% c("uM", "µM", "µg/ml") ~ "u",
    Unit == "nM" ~ "n", 
    Unit %in% c("mg/kg", "mM") ~ "m", 
  )) |> 
  dplyr::mutate(Concentrations=parse_number(`Concentrations Value`, trim_ws = TRUE, 
                                            locale = locale(decimal_mark = ",", grouping_mark = "."))) |> 
   dplyr::mutate(Concentrations = case_when(
    Unit == "u" ~ Concentrations *10^-6,
    Unit == "n" ~ Concentrations *10^-9, 
    Unit == "m" ~ Concentrations *10^-3)) |> 
  dplyr::mutate(`Concentrations Value`=parse_number(`Concentrations Value`, trim_ws = TRUE, 
                                            locale = locale(decimal_mark = ",", grouping_mark = ".")) |> 
                  format_concentrations()) |> 
  tidyr::unite(col ="Concentrations_ID", `Concentrations Value`, Unit, sep = "")

## format Durations, creating both 'Duration_ID' and 'Duration' as an integer value in Days ----
samples_metadata <- samples_metadata |> 
  ## extract last 6 numbers, as the only ones used for identification of samples downstream
  dplyr::mutate(Duration = parse_number(Duration_ID, trim_ws = TRUE, 
                                        locale = locale(decimal_mark = ".")), 
                Duration = dplyr::if_else(grepl("m$",  Duration_ID),
                                          Duration*30, Duration)) 

rm(updated_MoA_pathway)
```

2. In @lst-process-pheno2, we extract from each `replicate label` patterns enabling its mapping to [`Table of compounds`](data/Table of compounds_whole_2025-06-13.xlsx), and uses `sheet:'Drugs Mapping'` to map the prefix to its complete `DrugBank ID`.

```{r}
#| label: process-pheno2
#| lst-label: lst-process-pheno2
#| lst-cap: Retrive batches of interest.

batch_mapping <- readxl::read_xlsx("data/Table of compounds_whole_2025-06-13.xlsx",
                                       sheet = "Batch Mapping")
barcode_counts_paths <- batch_mapping |>
  dplyr::pull(Filename) |> unique()

## step 2) extract individual replicate IDs directly from sample experiences ----
ID_mapping <- purrr::map(barcode_counts_paths, function(Filename) {
  ## build path
  counts_path <- file.path("data","barcode-counts", 
                               paste0(Filename))
  
  ## extract replicate names (reading the header)
  replicates_ID <- strsplit(readLines(counts_path, n = 1), split = "\t")[[1]] |>
    str_subset("\\S") |> ## remove empty strings
    str_subset("barcode_id", negate = TRUE)

  ## ID: combination of letters, numbers and -, followed by '[1-4]_', starting the sample's name
  dataset_ID <- tibble::tibble(Filename = Filename, 
                               Date = stringr::str_extract(replicates_ID,
                                                           "(?<=_exp)[[:alnum:]]{6}"),
                               Replicates_ID = replicates_ID,
                               `Run date` = stringr::str_extract(replicates_ID,
                                                                 "(?<=_run)[[:alnum:]]{6}(?=_)"),
                               Concentrations_ID = stringr::str_extract(replicates_ID, 
                                                                        "(?<=[1-8]_)[[:digit:]]{3}[gmnux]{1}(?=_exp)")) |> 
    ## account for second notation syntax for concentrations
    dplyr::mutate(Concentrations_ID = if_else(is.na(Concentrations_ID), 
                                              stringr::str_extract(replicates_ID,
                                                                   "(?<=[1-8]_)[0-9]{1}\\.[0-9]{2}[gmnux]{1}(?=_exp)"),
                                              Concentrations_ID))
  
  ## Deal with two time notations
  if (grepl("281022(.*)gamme", Filename)) {
    dataset_ID <- dataset_ID |> 
      dplyr::mutate (Samples_ID = stringr::str_extract(replicates_ID,
                                                       "(?<=_)[[[:alnum:]]\\-]+(?=[1-8]_)"), 
                     Duration_ID=stringr::str_extract(replicates_ID,
                                                       "^[[[:alnum:]]\\.]{1,3}[dm](?=_)"))
  }
  else {
    dataset_ID <- dataset_ID |> 
      dplyr::mutate(Samples_ID = stringr::str_extract(replicates_ID,
                                                      "^[[[:alnum:]]\\-]+(?=[1-8]{1}_)"), 
                    Duration_ID = if_else(grepl("^Temps0", Replicates_ID),"0d", "9d"))
  }
                                 
  return(dataset_ID)
}) |>
  purrr::list_rbind()

## deal with specific p42 and p43
ID_mapping <- ID_mapping |>
  dplyr::mutate(Samples_ID = if_else(grepl("^p42", Replicates_ID), "p42", Samples_ID),
                Samples_ID = if_else(grepl("^p43", Replicates_ID), "p43", Samples_ID))

## detect bad extraction of patterns samples
# ID_mapping_missing <- ID_mapping |>
#   filter(if_any(everything(), is.na))

## step 3) map short compound IDs with full compound names ----
mapping_compounds <- readxl::read_xlsx("data/Table of compounds_whole_2025-06-13.xlsx",
                                sheet = "Drugs Mapping")
ID_mapping <- ID_mapping |> 
  inner_join(mapping_compounds, by = "Samples_ID")

ID_mapping <- ID_mapping |> 
  dplyr::inner_join(batch_mapping, 
                    by = dplyr::join_by(Filename, Date, `Run date`)) |> 
  dplyr::select(-`General Comments Per Batch`)

rm(batch_mapping, mapping_compounds)
```

3. In @lst-process-pheno3, @tbl-phenotype-metadata-saving is the final, curated metadata phenotype table, adhering to tidy principles [@tip-tidyformat]. This includes:
  
  i. Standardisation of Dates to `ISO 1860 Date format`.

```{r}
#| label: tbl-process-pheno3
#| lst-label: lst-process-pheno3
#| lst-cap: Save the final metadata annotations for barcodes.

## step 1) Use international date formats ----
replicates_metadata <- samples_metadata |> 
  dplyr::inner_join(ID_mapping,
                    by = dplyr::join_by(Compound, Date, `Run date`,
                                        Duration_ID, Concentrations_ID)) |> 
  ## convert to ISO 1860 Date format
  mutate(Date = lubridate::dmy(Date) |> format(),
         `Run date` = lubridate::dmy(`Run date`)) |> 
  # relocate colnames
  dplyr::select(Batch_ID, Filename, 
                Pathway, Old_Pathway, MoA, Old_MoA, 
                Compound, Samples_ID, Kept,
                Date, `Run date`, Duration, Duration_ID,
                Concentrations_Formatted, Concentrations_ID, Concentrations, 
                Replicates, Replicates_ID, Comments)

replicates_metadata_shortened <- replicates_metadata |> 
  dplyr::select(-Old_Pathway, -Old_MoA, -Samples_ID, -Kept, 
                -Duration_ID, -Concentrations_ID, 
                -Replicates, -Comments)

# replicates_metadata_deduplicated <- replicates_metadata |> 
#   dplyr::distinct(Replicates_ID, .keep_all = TRUE)
# all.equal(replicates_metadata, replicates_metadata_deduplicated)


## Step 2) save the tidy phenotype metatada table ----
readr::write_csv(replicates_metadata,
                 file = paste0("data/replicates_barcode_metadata_comprehensive_", 
                               today_date,".csv"))
readr::write_csv(replicates_metadata_shortened,
                 file = paste0("data/replicates_barcode_metadata_", today_date,".csv"))

flextable::flextable(head(replicates_metadata_shortened)) |> 
  autofit() |> 
  bold(part = "header")
```

::: {#tip-tidyformat .callout-tip title="Tidy Data Format (Key Principles)" collapse="true"}

1. **Each variable has its own column**.
2. **Each observation has its own row** – Every row corresponds to one observation.
3. **Each value has its own cell** – Each cell contains a single, unique value.

This format streamlines data wrangling, and generally speaking, data analysis and visualisation. In other words, prefer simpler `CSV` formats for the experimental design, and avoid *cell fusion* in Excel documents. Finally, for the formatted tabular representation in documentations, I use `flextable`.

:::

### Optional data quality checks

(Optional) @lst-check-pheno-data-1 and @lst-check-pheno-data-2 are *data integrity checks* to verify each replicate feature retrieved from its labelling is consistent with [`Table of compounds`](data/Table of compounds_whole_2025-06-13.xlsx), `sheet:'Experimental Design'`.

1. @lst-check-pheno-data-1 identifies all replicates that could not be mapped back to their metadata description stored under [`Table of compounds`](data/Table of compounds_whole_2025-06-13.xlsx), `sheet:'Drugs Mapping'.

```{r}
#| label: tbl-check-pheno-data
#| lst-label: lst-check-pheno-data-1 
#| lst-cap: "Extract discarded replicates"
#| tbl-cap: Uses `anti_join` between metadata table and barcode counts to identify replicates that could not be mapped back, and reciprocally.
#| tbl-subcap:
#|   - "Samples from [`Table of compounds`](data/Table of compounds_whole_2025-06-13.xlsx) that could not be mapped to any barcode replicates."
#|   - "Replicates barcode profiles stored under [./data/barcode-counts] with unknown metadata/not reported in general `Table of compounds`.
#| layout-ncol: 2

replicates_discarded <- dplyr::anti_join(ID_mapping, samples_metadata, 
                                         by = join_by(Date, `Run date`, Concentrations_ID,
                                                      Duration_ID, Compound))

pheno_data_unmapped <- dplyr::anti_join(samples_metadata,
                                        ID_mapping,
                                        by = join_by(Date, `Run date`, Concentrations_ID,
                                                     Duration_ID, Compound))

pheno_data_unmapped |> 
  arrange(Compound, Date, Concentrations_ID) |> 
  flextable() |> 
  bold(part = "header")
```

2. @tbl-check-pheno-data-2 is used for checking discrepancies between the number of barcode replicates reported in [`Table of compounds`](data/Table of compounds_whole_2025-06-13.xlsx) and the number of replicates actually observed in barcode counts. 

```{r}
#| label: tbl-check-pheno-data-2
#| lst-label: lst-check-pheno-data-2
#| lst-cap: Secound round of data wrangling quality controls on *counts* versus *phenotype data*, focusing on divergent number of replicates.
#| tbl-cap: Secound round of data wrangling quality controls on *counts* versus *phenotype data*, focusing on divergent number of replicates.

replicate_inconsistencies <- samples_metadata |> 
  dplyr::inner_join(ID_mapping, 
                    by = dplyr::join_by(Compound, 
                                        Date, `Run date`, 
                                        Duration_ID, Concentrations_ID)) |>
  group_by(Batch_ID, Compound, Date, Replicates, Concentrations_ID,Duration_ID) |>
  summarise(n = n()) |>
  filter(n != Replicates)

flextable(replicate_inconsistencies) |>
  autofit() |>
  bold(part = "header")

```





