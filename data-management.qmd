---
title: "Data management: metadata correction and cleansing"
---

## Reproducibility

I list below the R packages required to reproduce the analyses.

```{r}
#| label: setup

## data wrangling
library(dplyr)
library(tidyr)
library(stringr)
library(readr)
library(readxl)
library(purrr)

## reporting
library(flextable)

## auxiliary functions
source("R/utils.R")
# today_date <- "2025-04-28"
today_date <- format(Sys.Date(), "%Y-%m-%d")

```
## Barcode counts cleaning {#sec-select-exp}

- [Original Google Drive repository](https://drive.google.com/drive/folders/1pMSX4M4kHcDGxcsCzsMYHHM6VRvBHHUO).

- Below, we convert each `.TABULAR` file to its recommended `.tsv` file extension, and rename unequivocally the first `colname` into `barcode_id`:
    
```{r}
#| label: format-barcode-tsv
#| echo: true
#| eval: false
barcode_files <- list.files("./data/barcode-counts/", 
                               pattern = "exp.*\\.tabular", 
                               full.names = TRUE)

## change format + barcode name
barcode_matrices <- lapply(barcode_files, function(old_filename) {
  expression_matrix <- readxl::read_tsv(old_filename) |> 
    rename(barcode_id = 1)
  
  new_filename <- old_filename |> basename() |> tools::file_path_sans_ext()
  
  readr::write_tsv(expression_matrix, 
                   file = file.path("data", "barcode-counts", paste0(new_filename, ".tsv")))
  unlink(old_filename, force = TRUE)
  
})
```


- [I rename the first colname of each expression file as `barcode_id`, storing unequivocal tag.]{fg="red"}
- List of changes applied for easier mapping between replicates' barcode profiles and samples' metadata:

  - `exp130921`, switch from `Osimer1_001g_exp130921_run101121_28` to `Osimer1_001m_exp130921_run101121_28`, from `001g` to `001m` (*in-vivo* context), and switch from `Azacyt1_1,5u_exp130921_run290921_40` to `Azacyt1_1.50u_exp130921_run290921_40`, `1,5u` to `1.50u`^[*In-vivo* = cells injected in living mice, `control` versus `osermintinimb`.].
  - `exp200921`: switch from `Bafilo1_1,2n_exp200921_run111021_45` to `Bafilo1_1.20n_exp200921_run111021_45`, `1,2n` to `1.20n`. In addition, [the 4 control replicates of *dose-response* batch `exp200921_dose_response` are shared with standard experiment `exp200921.csv`.]{fg="red"}
  - `exp151121`: switch from `Mitomy1_002x_exp151121_run071221_37` to `Mitomy1_0.02u_exp151121_run071221_37`, `002x` to `0.02u`.
  - `exp070222`: switch from `Tunica1_0,5x_exp070222_run010322_05` to `Tunica1_0.50u_exp070222_run010322_05`, `0,5x` to `0.50u`.
  - `exp070222t25`: more comprehensive, so we keep the oldest one (no replicate `cDNA` missing). From `cDNA1_000u_exp281022_run141222_01` to `Contro1_000u_exp281022_run141222_01`! [What does `cDNA` refer to as?]{fg="red"}.
  - `exp281022t25`: one control and 3 Drug Compounds were sampled in **T25 flasks**. `P42` and `P43` are used for evaluating *barcode drift*, a technical artefact in relation with depth sequencing. [Most of the replicates lack of significant effect due to insufficient dose]{fg="red"}.
- `exp281022gamme` refers to the time course experiment.

We report in @tbl-overview-barcode-counts a summary of the barcode counts (File location, `batch_id`, and dimensions).

```{r}
#| label: tbl-overview-barcode-counts
#| tbl-cap: "Main Batch features."

barcode_files <- list.files("./data/barcode-counts/",
                            pattern = "exp.*\\.tsv",
                            full.names = TRUE)
barcode_summaries <- purrr::map(barcode_files, function(filename) {
  barcode_counts <- readr::read_tsv(filename, show_col_types = FALSE)
  experience_summary <- tibble::tibble(Filename = basename(filename),
                                       `Num Barcode IDs` = nrow(barcode_counts),
                                       `Num Replicates` = ncol(barcode_counts) - 1)
  return(experience_summary)
}) |>
  purrr::list_rbind()

barcode_summaries <- barcode_summaries |>
  dplyr::inner_join(readxl::read_excel("data/Table of compounds_whole_2025-06-13.xlsx",
    sheet = "Batch Mapping"),
    by = "Filename") |>
  dplyr::relocate(Batch_ID, .after = Filename) |>
  dplyr::relocate(`Num Barcode IDs`, `Num Replicates`, .after = `Run date`)

# openxlsx::write.xlsx("./data/temp_batch_mapping.xlsx", 
#                      asTable = TRUE, x = barcode_summaries)

flextable::flextable(barcode_summaries) |>
  bold(part = "header") |> 
  flextable::merge_v(j = c("Filename", "Batch_ID", "General Comments Per Batch"),
                      part = "body")
```

From @tbl-overview-barcode-counts: 

- **Number of barcode counts profiles**: `{r} length(barcode_files)`
- **Number of batches**:  `{r} length(unique(barcode_summaries$Date))`, retrieved on number of dates.
- **Number of runs**: `{r} length(unique(barcode_summaries$`Run date`))`, based on the total number of Barcode sequencing Runs. 
- **Number of experiments**: `{r} length(unique(barcode_summaries$Batch_ID))`, based on Batch IDs.
- **Technical covariates**: `{r} nrow(barcode_summaries)`, the Cartesian product of batches per run, as both Ending date of experiment, and sequencing can impact the output.


## Phenotype metadata cleaning {#sec-metadata-phenotypes}

Most of the R instructions reported in this section aim at rendering the `Table of compounds` file compliant with the `tidy` format, see @tip-tidyformat. These data-wrangling operations are split in 4 steps:

1. In @lst-process-pheno1, we homogenise `Concentrations`, `Date` and `Duration` to ISO standards, while dealing with erroneous missing values generated by fused Excel cells. [Besides, we removed special, non-ascii characters that could not be processed by visualisation plots, such as $NF-\kappa B$.]{fg="red"}

2. In @lst-process-pheno2, we retrieve from each individual barcode counts profile, the individual replicates ID identifying unequivocally each replicate. We set apart replicates that could be mapped back to original `Table of compounds` file.

3. In @lst-process-pheno3, we merge together in a comprehensive phenotype table the short `Samples_ID` (short term referring to drugs listed in `Compound` column), the full `Compound` (complete name of drugs) and map each of them to its complete list of replicates (from 2 to 8). We save the output in `data-derived`.

4. Finally, in @lst-check-pheno-data-1 and @lst-check-pheno-data-2, we perform several posterior *data integrity checks* to verify if i) we were able to map each individual replicate ID to its original ID in `Table of compounds`, and ii) if the number of replicates reported in [`Table of compounds`](data/Table of compounds_whole_2025-04-28.xlsx) was consistent with the number of barcode profiles.

```{r}
#| label: process-pheno1
#| lst-label: lst-process-pheno1
#| lst-cap: Coerce original Excel file reporting experimental design to tidy format.

pheno_colnames <- c(Old_Pathway = "Pathways", Old_MoA = "...2", 
                    Compound = "Samples", Replicates = "Replicates",
                    Original_Concentrations = "Concentrations", Date = "Experiment date",
                    `Run date` = "Run date", Duration_ID = "Duration", 
                    Kept = "Kept", Comments = "Comments")

## prune irrelevant colnames ----

pheno_data <- readxl::read_xlsx("data/Table of compounds_whole_2025-06-13.xlsx",
                                sheet = "Experimental Design",
                                col_types = c(rep("text", 3), "numeric", 
                                              rep("text", 4), "logical", "text")) |>
  dplyr::rename(dplyr::all_of(pheno_colnames)) |>
  tidyr::fill(Old_Pathway, Old_MoA, .direction = "down") |> 
  tidyr::fill(Compound, .direction = "down") |>
  dplyr::mutate(Old_Pathway = if_else(is.na(Old_Pathway), Old_MoA, Old_Pathway)) 

# integrate new pathway information from Luca ----
updated_MoA_pathway <- readxl::read_xlsx("data/Table of compounds_whole_2025-06-13.xlsx", 
                                                       sheet = "Pathway Mapping")
pheno_data <- pheno_data |> 
  dplyr::inner_join(updated_MoA_pathway,
                   by = join_by(Compound)) 

## format concentrations, creating both 'Concentrations_ID' and 'Concentrations' in Moles ----
pheno_data <- pheno_data |> 
  dplyr::mutate(Concentrations=if_else(grepl("^(Control|P42|P43)", Compound), "000 uM", Original_Concentrations)) |> 
  dplyr::mutate(Concentrations=if_else(Compound == "Osimertinb+sorafenib", "015 uM", Concentrations)) |>
  tidyr::separate_wider_delim(Concentrations, delim = " ", names = c("Concentrations Value", "Unit"), cols_remove = FALSE) |>
  dplyr::mutate(Unit = case_when(
    Unit %in% c("uM", "µM", "µg/ml") ~ "u",
    Unit == "nM" ~ "n", 
    Unit %in% c("mg/kg", "mM") ~ "m", 
  )) |> 
  dplyr::mutate(Concentrations=parse_number(`Concentrations Value`, trim_ws = TRUE, 
                                            locale = locale(decimal_mark = ",", grouping_mark = "."))) |> 
   dplyr::mutate(Concentrations = case_when(
    Unit == "u" ~ Concentrations *10^-6,
    Unit == "n" ~ Concentrations *10^-9, 
    Unit == "m" ~ Concentrations *10^-3)) |> 
  dplyr::mutate(`Concentrations Value`=parse_number(`Concentrations Value`, trim_ws = TRUE, 
                                            locale = locale(decimal_mark = ",", grouping_mark = ".")) |> 
                  format_concentrations()) |> 
  tidyr::unite(col ="Concentrations_ID", `Concentrations Value`, Unit, sep = "")

## format Durations, creating both 'Duration_ID' and 'Duration' as an integer value in Days ----
pheno_data <- pheno_data |> 
  ## extract last 6 numbers, as the only ones used for identification of samples downstream
  dplyr::mutate(Duration = parse_number(Duration_ID, trim_ws = TRUE, 
                                        locale = locale(decimal_mark = ".")), 
                Duration = dplyr::if_else(grepl("m$",  Duration_ID),
                                          Duration*30, Duration)) 

rm(updated_MoA_pathway)
```

::: {.callout-important title="Metadata inconsistencies and Conversion to UIC Units" collapse="true"}

- [In `Run date`, when there was a range instead of a fixed Date, I kept only the end of the interval.]{fg="red"}

:::

In @lst-process-pheno2 and @lst-process-pheno3, we identify which raw barcode replicates could not be mapped back, **keeping only replicates with curated metadata information.**.

```{r}
#| label: process-pheno2
#| lst-label: lst-process-pheno2
#| lst-cap: Retrive batches of interest.

## retrieve filenames
batch_mapping <- readxl::read_xlsx("data/Table of compounds_whole_2025-06-13.xlsx",
                                       sheet = "Batch Mapping")
barcode_counts_paths <- batch_mapping |>
  dplyr::pull(Filename) |> unique()

## step 2) extract individual replicate IDs directly from sample experiences ----
## Filename <- "exp281022.csv"; Batch_ID <- "exp281022"; Date <- "281022"
ID_mapping <- purrr::map(barcode_counts_paths, function(Filename) {
  ## build path
  counts_path <- file.path("data","barcode-counts", 
                               paste0(Filename))
  
  ## extract replicate names (reading the header)
  replicates_ID <- strsplit(readLines(counts_path, n = 1), split = "\t")[[1]] |>
    str_subset("\\S") |> ## remove empty strings
    str_subset("barcode_id", negate = TRUE)

  ## ID: combination of letters, numbers and -, followed by '[1-4]_', starting the sample's name
  dataset_ID <- tibble::tibble(Filename = Filename, 
                               Date = stringr::str_extract(replicates_ID,
                                                           "(?<=_exp)[[:alnum:]]{6}"),
                               Replicates_ID = replicates_ID,
                               `Run date` = stringr::str_extract(replicates_ID,
                                                                 "(?<=_run)[[:alnum:]]{6}(?=_)"),
                               Concentrations_ID = stringr::str_extract(replicates_ID, 
                                                                        "(?<=[1-8]_)[[:digit:]]{3}[gmnux]{1}(?=_exp)")) |> 
    ## account for second notation syntax for concentrations
    dplyr::mutate(Concentrations_ID = if_else(is.na(Concentrations_ID), 
                                              stringr::str_extract(replicates_ID,
                                                                   "(?<=[1-8]_)[0-9]{1}\\.[0-9]{2}[gmnux]{1}(?=_exp)"),
                                              Concentrations_ID))
  
  ## Deal with two time notations
  if (grepl("281022(.*)gamme", Filename)) {
    dataset_ID <- dataset_ID |> 
      dplyr::mutate (Samples_ID = stringr::str_extract(replicates_ID,
                                                       "(?<=_)[[[:alnum:]]\\-]+(?=[1-8]_)"), 
                     Duration_ID=stringr::str_extract(replicates_ID,
                                                       "^[[[:alnum:]]\\.]{1,3}[dm](?=_)"))
  }
  else {
    dataset_ID <- dataset_ID |> 
      dplyr::mutate(Samples_ID = stringr::str_extract(replicates_ID,
                                                      "^[[[:alnum:]]\\-]+(?=[1-8]{1}_)"), 
                    Duration_ID = if_else(grepl("^Temps0", Replicates_ID),"0d", "9d"))
  }
                                 
  return(dataset_ID)
}) |>
  purrr::list_rbind()

## deal with specific p42 and p43
ID_mapping <- ID_mapping |>
  dplyr::mutate(Samples_ID = if_else(grepl("^p42", Replicates_ID), "p42", Samples_ID),
                Samples_ID = if_else(grepl("^p43", Replicates_ID), "p43", Samples_ID))

## detect bad extraction of patterns samples
# ID_mapping_missing <- ID_mapping |>
#   filter(if_any(everything(), is.na))

## step 3) map short compound IDs with full compound names ----
mapping_compounds <- readxl::read_xlsx("data/Table of compounds_whole_2025-06-13.xlsx",
                                sheet = "Drugs Mapping")
ID_mapping <- ID_mapping |> 
  inner_join(mapping_compounds, by = "Samples_ID")
## test <- ID_mapping |> anti_join(mapping_compounds, by = "Samples_ID")
## test2 <- mapping_compounds |> anti_join(ID_mapping, by = "Samples_ID")

ID_mapping <- ID_mapping |> 
  dplyr::inner_join(batch_mapping, 
                    by = dplyr::join_by(Filename, Date, `Run date`)) |> 
  dplyr::select(-`General Comments Per Batch`)

rm(batch_mapping, mapping_compounds)
```


Finally, in @lst-check-pheno-data-1, we map all replicates (one column in a given barcode count matrix) to its comprehensive metadata description (stored in `Tables of compounds`), using as **primary and foreign keys** the following 6 variables: `Batch_ID`,  `Compound`, `Duration_ID`, `Run date`, `Date`, and `Concentrations_ID`.

```{r}
#| label: tbl-check-pheno-data
#| lst-label: lst-check-pheno-data-1 
#| lst-cap: "Extract discarded replicates"
#| tbl-cap: Identify set of experiences reported in `Table of compounds` that could not be mapped against their corresponding Barcode counts replicates. We check this information with an `anti_join` between original *phenotype* and *counts*, returning samples from `Table of Compound` that could not have been mapped back.

replicates_discarded <- dplyr::anti_join(ID_mapping, pheno_data, 
                                         by = join_by(Date, `Run date`, Concentrations_ID,
                                                      Duration_ID, Compound))

pheno_data_unmapped <- dplyr::anti_join(pheno_data,
                                        ID_mapping,
                                        by = join_by(Date, `Run date`, Concentrations_ID,
                                                     Duration_ID, Compound))

pheno_data_unmapped |> 
  arrange(Compound, Date, Concentrations_ID) |> 
  flextable() |> 
  bold(part = "header")
```

In @tbl-check-pheno-data-2, we check discrepancies between the number of barcode replicates reported in `Table of compounds` with the number of replicates available in barcode counts matrices. [And it turned out that `compound`: XAV-939, `Date`: 220322, is reported with 4 replicates, while only 2 could be found in [`exp220322` barcode count matrix](./data/barcode-counts/exp220322.csv)]{fg="red"}

```{r}
#| label: tbl-check-pheno-data-2
#| lst-label: lst-check-pheno-data-2
#| lst-cap: Secound round of data wrangling quality controls on *counts* versus *phenotype data*, focusing on divergent number of replicates.
#| tbl-cap: Secound round of data wrangling quality controls on *counts* versus *phenotype data*, focusing on divergent number of replicates.

replicate_inconsistencies <- pheno_data |> 
  dplyr::inner_join(ID_mapping, 
                    by = dplyr::join_by(Compound, 
                                        Date, `Run date`, 
                                        Duration_ID, Concentrations_ID)) |>
  group_by(Batch_ID, Compound, Date, Replicates, Concentrations_ID,Duration_ID) |>
  summarise(n = n()) |>
  filter(n != Replicates)

flextable(replicate_inconsistencies) |>
  autofit() |>
  bold(part = "header")

```

### Save phenotype Metadata

By applying all the formatting analyses reported in @sec-metadata-phenotypes, we generate in @tbl-phenotype-metadata-saving a global metadata phenotypic table, adhering to tidy principles [@tip-tidyformat]. 

::: {#tip-tidyformat .callout-tip title="Tidy Data Format (Key Principles)" collapse="true"}

1. **Each variable has its own column**.
2. **Each observation has its own row** – Every row corresponds to one observation.
3. **Each value has its own cell** – Each cell contains a single, unique value.

This format streamlines data wrangling, and generally speaking, data analysis and visualisation. In other words, prefer simpler `CSV` formats for the experimental design, and avoid *cell fusion* in Excel documents. Finally, for the formatted tabular representation in documentations, I use `flextable`.

:::

```{r}
#| label: tbl-phenotype-metadata-saving
#| lst-label: lst-save-pheno-metadata
#| lst-cap: Save the final metadata annotations for barcodes, using Today's date for historical versioning.

## step 4) Use international date formats ----
pheno_data_formatted <- pheno_data |> 
  dplyr::inner_join(ID_mapping,
                    by = dplyr::join_by(Compound, Date, `Run date`,
                                 Duration_ID, Concentrations_ID)) |> 
  dplyr::select(Batch_ID, Pathway, MoA,
                Compound, Samples_ID, 
                Replicates, Replicates_ID,
                Concentrations, Concentrations_ID, 
                Date, `Run date`, Duration, Duration_ID) |> 
  ## convert to ISO 1860 Date format
  mutate(Date = lubridate::dmy(Date) |> format(),
         `Run date` = lubridate::dmy(`Run date`), 
  ## artificially de-duplicate controls for exp, simplify the analytical workflow 
  Replicates_ID = dplyr::if_else(Batch_ID %in% c("exp200921_dose_response") &
                                   Compound == "Control",
                                 gsub("exp200921_", "exp200921_dose_response_", Replicates_ID),
                                 Replicates_ID))

## 2) QC: guarantee uniqueness of the replicates
pheno_data_deduplicated <- pheno_data_formatted |> 
  dplyr::distinct(Replicates_ID, .keep_all = TRUE)
all.equal(pheno_data_deduplicated, pheno_data_formatted)

## 3) save as .xlsx file discarded and preserved replicates

barcode_counts_summaries <- list("kept counts" = kept_barcode_summaries,
                                 "kept compounds" = pheno_data,
                                 "kept replicates" = pheno_data_formatted |> 
                                   select(Compound, Replicates_ID),
                                 "discarded counts" = barcode_discarded_summaries, 
                                 "discarded compounds"=pheno_data_discarded, 
                                 "discarded replicates" = replicates_discarded)

openxlsx::write.xlsx(x = barcode_counts_summaries,
                     file = paste0("./data/logs/barcode_metadata_overview_",
                                   today_date,".xlsx"),
                     overwrite = TRUE, asTable = TRUE)


## 4) save the tidy phenotype metatada table ----
readr::write_csv(pheno_data_formatted,
                 file = paste0("data/pheno_data_metadata_", today_date,".csv"))

flextable::flextable(head(pheno_data_formatted)) |> 
  autofit() |> 
  bold(part="header")
```


**Conclusion**: on a total of `{r} nrow(ID_mapping)`, `{r} nrow(pheno_data_formatted)` replicates are kept, and `{r} nrow(replicates_discarded)` replicates were removed.

