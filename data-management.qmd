---
title: "Data management: metadata correction and cleansing"
---

## Reproducibility

I list below the R packages required to reproduce the analyses.

```{r}
#| label: setup

## data wrangling
library(dplyr)
library(tidyr)
library(stringr)
library(readr)
library(readxl)
library(purrr)

## reporting
library(flextable)

## auxiliary functions
source("R/utils.R")
# today_date <- "2025-04-28"
today_date <- format(Sys.Date(), "%Y-%m-%d")

```

- [Original Google Drive repository](https://drive.google.com/drive/folders/1pMSX4M4kHcDGxcsCzsMYHHM6VRvBHHUO).

- Below, we convert each `.TABULAR` file to its recommended `.tsv` file extension, and rename unequivocally the first `colname` into `barcode_id`:
    
```{r}
#| label: format-barcode-tsv
#| echo: true
#| eval: false
barcode_files <- list.files("./data/barcode-counts/", 
                               pattern = "exp.*\\.tabular", 
                               full.names = TRUE)

## change format + barcode name
barcode_matrices <- lapply(barcode_files, function(old_filename) {
  expression_matrix <- readxl::read_tsv(old_filename) |> 
    rename(barcode_id = 1)
  
  new_filename <- old_filename |> basename() |> tools::file_path_sans_ext()
  
  readr::write_tsv(expression_matrix, 
                   file = file.path("data", "barcode-counts", paste0(new_filename, ".tsv")))
  unlink(old_filename, force = TRUE)
  
})
```

- List of changes applied for easier mapping between replicates' barcode profiles and samples' metadata:

  - `exp130921_in_vivo`, switch from `Osimer1_001g_exp130921_run101121_28` to `Osimer1_001m_exp130921_run101121_28`, from `001g` to `001m`
  - `exp130921`: switch from `Azacyt1_1,5u_exp130921_run290921_40` to `Azacyt1_1.50u_exp130921_run290921_40`, `1,5u` to `1.50u`.
  - `exp200921`: switch from `Bafilo1_1,2n_exp200921_run111021_45` to `Bafilo1_1.20n_exp200921_run111021_45`, `1,2n` to `1.20n`.
  - `exp151121`: switch from `Mitomy1_002x_exp151121_run071221_37` to `Mitomy1_0.02u_exp151121_run071221_37`, `002x` to `0.02u`.
  - `exp070222`: switch from `Tunica1_0,5x_exp070222_run010322_05` to `Tunica1_0.50u_exp070222_run010322_05`, `0,5x` to `0.50u`.
  - `exp070222t25`: more comprehensive, so we keep the oldest one (no replicate `cDNA` missing). From `cDNA1_000u_exp281022_run141222_01` to `Contro1_000u_exp281022_run141222_01`! [What does `cDNA` refer to as?]{fg="red"}.
    
## Barcode counts cleaning {#sec-select-exp}


```{r}
#| label: select-expression-300821
#| eval: false
#| echo: false


exp300821 <- readr::read_csv("data/barcode-counts/exp300821.csv") 

## fake additional colnames, containing only missing colnames
exp300821_whole <- readr::read_csv2("old-data-backup/data-raw/barcode-counts/exp300821.csv") |> 
  rename(barcode_id = 1)
selected_dataset <- compare_dataframes(exp300821, exp300821_whole)

setdiff(exp300821$barcode_id, exp300821_whole$barcode_id)
cor(exp300821$Osimer4_100n_exp300821_run290921_08, exp300821_whole$Osimer4_100n_exp300821_run290921_08)

readr::write_csv(exp300821, "data/barcode-counts/exp300821.csv")
```

```{r}
#| label: rename-erroneous-date-271221
#| eval: false
#| echo: true
#| lst-label: lst-rename-bad-date
#| lst-cap: Update labelling of latest experience.

exp271221 <- readr::read_csv("data/barcode-counts/exp271221.csv") 
exp271221_whole <- readr::read_csv2("old-data-backup/data-raw/barcode-counts/exp211221cor.csv") |> 
  rename(barcode_id = 1)
selected_dataset <- compare_dataframes(exp271221, exp271221_whole)

file.rename("data/barcode-counts/exp211221.csv", "data/barcode-counts/exp271221.csv") 
```

[In @lst-rename-bad-date, we rename expression file `exp211221.csv` into `exp271221.csv`, relying on date annotations.]{fg="red"}

```{r}
#| label: discriminate-200921-dose-response-standard
#| eval: false
#| echo: false

exp200921_standard <- readr::read_csv("data/barcode-counts/exp200921.csv") 
exp200921_dose_response <- readr::read_csv("data/barcode-counts/exp200921_dose_response.csv")


exp200921_global <- readr::read_tsv("data/barcode-counts/exp200921_whole exp.tabular") |> dplyr::rename(barcode_id="key")

## able to map all samples from global to either dose response or standard
setdiff(colnames(exp200921_global), 
        union(colnames(exp200921_dose_response), colnames(exp200921_standard)))

## all dose response variables can be found in whole experiment
setdiff(colnames(exp200921_dose_response), colnames(exp200921_global))
readr::write_csv(exp200921_global |> 
                   dplyr::select(dplyr::all_of(colnames(exp200921_dose_response))), 
                 "data/barcode-counts/exp200921_dose_response.csv")

## 5 compounds (so 5*4=20) replicates are not avalaible in whole experiment
## waiting for confirmation before removing them
intersect(colnames(exp200921_standard), colnames(exp200921_global))
print("\n\n")
setdiff(colnames(exp200921_standard), colnames(exp200921_global))

cat(intersect(colnames(exp200921_standard), colnames(exp200921_global)), 
    file = "./data/logs/replicates_preserved_200921.txt", sep = "\n")
cat(setdiff(colnames(exp200921_standard), colnames(exp200921_global)), 
    file = "./data/logs/replicates_discarded_200921.txt", sep = "\n")

## selected_dataset <- compare_dataframes(exp200921_standard, exp200921_dose_response)
```

[While the *dose-response* experience `exp200921_dose_response` exhibits distinct biological objective, it turned out that the 4 control biological replicates are shared with classical compound response comparison `exp200921.csv`. However, **the number of sequenced barcode IDs differ in both experiences!!** In addition, note that `exp200921.csv` has been tagged as discarded, except for the Controls!!]{fg="red"}
  
Code snippets in @lst-281022 and @lst-281022-time-course aim at replacing unprecise labelling of barcode IDs (no concentration, no time duration, ...) in the 2022 batch experiences.

```{r}
#| label: select-expression-281022
#| eval: false
#| echo: true
#| lst-label: lst-281022
#| lst-cap: Update labelling of latest experience.

## extract old colnames
exp281022_expression <- readr::read_csv("data/barcode-counts/exp281022.csv") 
## cat(colnames(exp281022_expression), file = "281022_old_labels.txt", sep = "\n")

## extract mapping old_names with new_names
mapping_old_new_281022 <- readxl::read_excel("data/Table of compounds_whole_2025-04-28.xlsx", 
                                             sheet = "Sample Mapping 281022")

labels_old_new_281022 <- setNames(object = mapping_old_new_281022$OLD_replicate_label, 
                                  nm = mapping_old_new_281022$NEW_replicate_label)

## apply change labelling
exp281022_expression <- exp281022_expression |> 
  dplyr::rename(dplyr::all_of(labels_old_new_281022))

readr::write_csv(exp281022_expression, "data/barcode-counts/exp281022.csv")
```


```{r}
#| label: select-expression-281022-time-course
#| eval: false
#| echo: true
#| lst-label: lst-281022-time-course
#| lst-cap: Update time course experiences.

exp281022_expression_timecourse <- readr::read_csv("data/barcode-counts/exp281022_time_course.csv") 
## cat(colnames(exp281022_expression_timecourse), file = "281022_timecourse_old_labels.txt", sep = "\n")

## update colnames ----

mapping_old_new_time_course <- read_excel("data/Table of compounds_whole_2025-04-28.xlsx", 
                                     sheet = "Sample Mapping Time Course")

labels_old_new_time_course <- setNames(object = mapping_old_new_time_course$OLD_replicate_label, 
                                       nm = mapping_old_new_time_course$NEW_replicate_label)

## apply change labelling
exp281022_expression_timecourse <- exp281022_expression_timecourse |> 
  dplyr::rename(dplyr::all_of(labels_old_new_time_course))

readr::write_csv(exp281022_expression_timecourse,
                 "data/barcode-counts/exp281022_time_course.csv")

## To evaluate whether controls are different between experiment 281022 and 281022 Time Course
controls_exp281022 <- exp281022_expression |> 
  select(key_barcode, dplyr::matches("^ctl")) |> 
  dplyr::inner_join(exp281022_expression_timecourse |> 
                      select(key_barcode, dplyr::matches("^Ctrl")),
                    by="key_barcode")
cor(controls_exp281022$ctl2, controls_exp281022$Ctrl2) ## they strongly correlate with each other, but not a perfect match -> controls are indeed distinct

```


<!-- ### Additional comments -->

<!-- - `exp130921_in_vivo`: cells injected in living mice (control versus osermintinimb). -->
<!-- - `exp281022`: control, protac, cetuximab and gefitinib ($n=4$ replicates each time) were sampled in T25 flasks. P42 and P43 correspond to cells grown without treatment for 42 or 43 passages, and were used for evaluating *barcode drift* technical artefact. -->
<!-- - `exp281022_time_course`: time course experiment. -->

### Data management good practices

Things to consider:

- [I rename the first colname of each expression file as `barcode_id`, storing unequivocal tag.]{fg="red"}

<!-- ### Overview of barcode counts -->

<!-- We report in @tbl-overview-barcode-counts a summary of the barcode counts (File location, `batch_id`, and dimensions of the counts matrix) considered for the generation of the Heatmaps, and the construction of a drug-drug network. -->

<!-- ```{r} -->
<!-- #| label: tbl-overview-barcode-counts -->
<!-- #| tbl-cap: "Overview of the Barcoding Batches." -->
<!-- #| tbl-subcap: -->
<!-- #|   - "Kept Batches" -->
<!-- #|   - "Removed batches" -->
<!-- #| layout-ncol: 2 -->

<!-- ## 1) summarise kept batches ---- -->
<!-- barcode_files <- list.files("./data/barcode-counts/", -->
<!--                             pattern = "exp.*\\.csv", -->
<!--                             full.names = TRUE) -->

<!-- kept_barcode_summaries <- purrr::map(barcode_files, function(filename) { -->
<!--   barcode_counts <- readr::read_csv(filename, show_col_types = FALSE) -->
<!--   experience_name <- filename |> basename() |> tools::file_path_sans_ext() -->
<!--   experience_summary <- tibble::tibble(`Experience Name`= experience_name, -->
<!--                                        Features= paste0("Barcode matrix contains: ", -->
<!--                                                         nrow(barcode_counts), -->
<!--                                                         " unique barcode IDs, and ", -->
<!--                                                         ncol(barcode_counts)-1, " replicates.")) -->
<!--   return(experience_summary) -->
<!-- }) |> -->
<!--   purrr::list_rbind() -->
<!-- flextable::flextable(kept_barcode_summaries) |>  -->
<!--   bold(part="header") -->

<!-- ## 2) summarise discarded batches ---- -->
<!-- discarded_files <- list.files("./data/barcode-counts/temp discarded/", -->
<!--                             pattern = "exp.*\\.csv", -->
<!--                             full.names = TRUE) -->

<!-- ## change format + barcode name -->
<!-- barcode_discarded_summaries <- purrr::map(discarded_files, function(filename) { -->
<!--   barcode_counts <- readr::read_csv(filename, show_col_types = FALSE) -->
<!--   experience_name <- filename |> basename() |> tools::file_path_sans_ext() -->
<!--   experience_summary <- tibble::tibble(`Experience Name`= experience_name, -->
<!--                                        Features= paste0("Barcode matrix contains: ", -->
<!--                                                         nrow(barcode_counts), -->
<!--                                                         " unique barcode IDs, and ", -->
<!--                                                         ncol(barcode_counts)-1, " replicates.")) -->
<!--   return(experience_summary) -->
<!-- }) |> -->
<!--   purrr::list_rbind() -->

<!-- flextable::flextable(barcode_discarded_summaries) |>  -->
<!--   bold(part="header") -->

<!-- ``` -->

<!-- From @tbl-overview-barcode-counts, `{r} nrow(kept_barcode_summaries)` barcode experiences are included in the analysis, whereas `{r} nrow(barcode_discarded_summaries)` batches/experiences are filtered out. -->


## Phenotype metadata cleaning {#sec-metadata-phenotypes}

- [General question: what's the difference between `Run Date` and `Experiment Date`?]{fg="red"}

Most of the R instructions reported in this section aim at rendering the `Table of compounds` file compliant with the `tidy` format, see @tip-tidyformat. These data-wrangling operations are split in 4 steps:

1. In @lst-process-pheno1, we homogenise `Concentrations`, `Date` and `Duration` to ISO standards, while dealing with erroneous missing values generated by fused Excel cells. [Besides, we removed special, non-ascii characters that could not be processed by visualisation plots, such as $NF-\kappa B$.]{fg="red"}

2. In @lst-process-pheno2, we retrieve from each individual barcode counts profile, the individual replicates ID identifying unequivocally each replicate. We set apart replicates that could be mapped back to original `Table of compounds` file.

3. In @lst-process-pheno3, we merge together in a comprehensive phenotype table the short `Samples_ID` (short term referring to drugs listed in `Compound` column), the full `Compound` (complete name of drugs) and map each of them to its complete list of replicates (from 2 to 8). We save the output in `data-derived`.

4. Finally, in @lst-check-pheno-data-1 and @lst-check-pheno-data-2, we perform several posterior *data integrity checks* to verify if i) we were able to map each individual replicate ID to its original ID in `Table of compounds`, and ii) if the number of replicates reported in [`Table of compounds`](data/Table of compounds_whole_2025-04-28.xlsx) was consistent with the number of barcode profiles.

```{r}
#| label: process-pheno1
#| lst-label: lst-process-pheno1
#| lst-cap: Coerce original Excel file reporting experimental design to tidy format.

pheno_colnames <- c(Old_Pathway = "Pathways", Old_MoA = "...2", 
                    Compound = "Samples", Replicates = "Replicates",
                    Original_Concentrations = "Concentrations", Date = "Experiment date",
                    `Run date` = "Run date", Duration_ID = "Duration", 
                    Kept = "Kept", Comments = "Comments")

## prune irrelevant colnames ----

pheno_data <- readxl::read_xlsx("data/Table of compounds_whole_2025-06-13.xlsx",
                                sheet = "Experimental Design",
                                col_types = c(rep("text", 3), "numeric", 
                                              rep("text", 4), "logical", "text")) |>
  dplyr::rename(dplyr::all_of(pheno_colnames)) |>
  tidyr::fill(Old_Pathway, Old_MoA, .direction = "down") |> 
  tidyr::fill(Compound, .direction = "down") |>
  dplyr::mutate(Old_Pathway = if_else(is.na(Old_Pathway), Old_MoA, Old_Pathway)) 

# integrate new pathway information from Luca ----
updated_MoA_pathway <- readxl::read_xlsx("data/Table of compounds_whole_2025-06-13.xlsx", 
                                                       sheet = "Pathway Mapping")
pheno_data <- pheno_data |> 
  dplyr::inner_join(updated_MoA_pathway,
                   by = join_by(Compound)) 

## format concentrations, creating both 'Concentrations_ID' and 'Concentrations' in Moles ----
pheno_data <- pheno_data |> 
  dplyr::mutate(Concentrations=if_else(grepl("^(Control|P42|P43)", Compound), "000 uM", Original_Concentrations)) |> 
  dplyr::mutate(Concentrations=if_else(Compound == "Osimertinb+sorafenib", "015 uM", Concentrations)) |>
  tidyr::separate_wider_delim(Concentrations, delim = " ", names = c("Concentrations Value", "Unit"), cols_remove = FALSE) |>
  dplyr::mutate(Unit = case_when(
    Unit %in% c("uM", "µM", "µg/ml") ~ "u",
    Unit == "nM" ~ "n", 
    Unit %in% c("mg/kg", "mM") ~ "m", 
  )) |> 
  dplyr::mutate(Concentrations=parse_number(`Concentrations Value`, trim_ws = TRUE, 
                                            locale = locale(decimal_mark = ",", grouping_mark = "."))) |> 
   dplyr::mutate(Concentrations = case_when(
    Unit == "u" ~ Concentrations *10^-6,
    Unit == "n" ~ Concentrations *10^-9, 
    Unit == "m" ~ Concentrations *10^-3)) |> 
  dplyr::mutate(`Concentrations Value`=parse_number(`Concentrations Value`, trim_ws = TRUE, 
                                            locale = locale(decimal_mark = ",", grouping_mark = ".")) |> 
                  format_concentrations()) |> 
  tidyr::unite(col ="Concentrations_ID", `Concentrations Value`, Unit, sep = "")

## format Durations, creating both 'Duration_ID' and 'Duration' as an integer value in Days ----
pheno_data <- pheno_data |> 
  ## extract last 6 numbers, as the only ones used for identification of samples downstream
  dplyr::mutate(Duration = parse_number(Duration_ID, trim_ws = TRUE, 
                                        locale = locale(decimal_mark = ".")), 
                Duration = dplyr::if_else(grepl("m$",  Duration_ID),
                                          Duration*30, Duration)) 

rm(updated_MoA_pathway)
```

::: {.callout-important title="Metadata inconsistencies and Conversion to UIC Units" collapse="true"}

- [In `Run date`, when there was a range instead of a fixed Date, I kept only the end of the interval.]{fg="red"}

:::

In @lst-process-pheno2 and @lst-process-pheno3, we identify which raw barcode replicates could not be mapped back, **keeping only replicates with curated metadata information.**.

```{r}
#| label: process-pheno2
#| lst-label: lst-process-pheno2
#| lst-cap: Retrive batches of interest.

## retrieve filenames
batch_mapping <- readxl::read_xlsx("data/Table of compounds_whole_2025-06-13.xlsx",
                                       sheet = "Batch Mapping")
barcode_counts_paths <- batch_mapping |>
  dplyr::pull(Filename) |> unique()

## step 2) extract individual replicate IDs directly from sample experiences ----
## Filename <- "exp281022.csv"; Batch_ID <- "exp281022"; Date <- "281022"
ID_mapping <- purrr::map(barcode_counts_paths, function(Filename) {
  ## build path
  counts_path <- file.path("data","barcode-counts", 
                               paste0(Filename))
  
  ## extract replicate names (reading the header)
  replicates_ID <- strsplit(readLines(counts_path, n = 1), split = "\t")[[1]] |>
    str_subset("\\S") |> ## remove empty strings
    str_subset("barcode_id", negate = TRUE)

  ## ID: combination of letters, numbers and -, followed by '[1-4]_', starting the sample's name
  dataset_ID <- tibble::tibble(Filename = Filename, 
                               Date = stringr::str_extract(replicates_ID,
                                                           "(?<=_exp)[[:alnum:]]{6}"),
                               Replicates_ID = replicates_ID,
                               `Run date` = stringr::str_extract(replicates_ID,
                                                                 "(?<=_run)[[:alnum:]]{6}(?=_)"),
                               Concentrations_ID = stringr::str_extract(replicates_ID, 
                                                                        "(?<=[1-8]_)[[:digit:]]{3}[gmnux]{1}(?=_exp)")) |> 
    ## account for second notation syntax for concentrations
    dplyr::mutate(Concentrations_ID = if_else(is.na(Concentrations_ID), 
                                              stringr::str_extract(replicates_ID,
                                                                   "(?<=[1-8]_)[0-9]{1}\\.[0-9]{2}[gmnux]{1}(?=_exp)"),
                                              Concentrations_ID))
  
  ## Deal with two time notations
  if (grepl("281022(.*)gamme", Filename)) {
    dataset_ID <- dataset_ID |> 
      dplyr::mutate (Samples_ID = stringr::str_extract(replicates_ID,
                                                       "(?<=_)[[[:alnum:]]\\-]+(?=[1-8]_)"), 
                     Duration_ID=stringr::str_extract(replicates_ID,
                                                       "^[[[:alnum:]]\\.]{1,3}[dm](?=_)"))
  }
  else {
    dataset_ID <- dataset_ID |> 
      dplyr::mutate(Samples_ID = stringr::str_extract(replicates_ID,
                                                      "^[[[:alnum:]]\\-]+(?=[1-8]{1}_)"), 
                    Duration_ID = if_else(grepl("^Temps0", Replicates_ID),"0d", "9d"))
  }
                                 
  return(dataset_ID)
}) |>
  purrr::list_rbind()

## deal with specific p42 and p43
ID_mapping <- ID_mapping |>
  dplyr::mutate(Samples_ID = if_else(grepl("^p42", Replicates_ID), "p42", Samples_ID),
                Samples_ID = if_else(grepl("^p43", Replicates_ID), "p43", Samples_ID))

## detect bad extraction of patterns samples
# ID_mapping_missing <- ID_mapping |>
#   filter(if_any(everything(), is.na))

## step 3) map short compound IDs with full compound names ----
mapping_compounds <- readxl::read_xlsx("data/Table of compounds_whole_2025-06-13.xlsx",
                                sheet = "Drugs Mapping")
ID_mapping <- ID_mapping |> 
  inner_join(mapping_compounds, by = "Samples_ID")
## test <- ID_mapping |> anti_join(mapping_compounds, by = "Samples_ID")
## test2 <- mapping_compounds |> anti_join(ID_mapping, by = "Samples_ID")

ID_mapping <- ID_mapping |> 
  dplyr::inner_join(batch_mapping, 
                    by = dplyr::join_by(Filename, Date, `Run date`)) |> 
  dplyr::select(-`General Comments Per Batch`)

rm(batch_mapping, mapping_compounds)
```


Finally, in @lst-check-pheno-data-1, we map all replicates (one column in a given barcode count matrix) to its comprehensive metadata description (stored in `Tables of compounds`), using as **primary and foreign keys** the following 6 variables: `Batch_ID`,  `Compound`, `Duration_ID`, `Run date`, `Date`, and `Concentrations_ID`.

```{r}
#| label: tbl-check-pheno-data
#| lst-label: lst-check-pheno-data-1 
#| lst-cap: "Extract discarded replicates"
#| tbl-cap: Identify set of experiences reported in `Table of compounds` that could not be mapped against their corresponding Barcode counts replicates. We check this information with an `anti_join` between original *phenotype* and *counts*, returning samples from `Table of Compound` that could not have been mapped back.

replicates_discarded <- dplyr::anti_join(ID_mapping, pheno_data, 
                                         by = join_by(Date, `Run date`, Concentrations_ID,
                                                      Duration_ID, Compound))

pheno_data_unmapped <- dplyr::anti_join(pheno_data,
                                        ID_mapping,
                                        by = join_by(Date, `Run date`, Concentrations_ID,
                                                     Duration_ID, Compound))

pheno_data_unmapped |> 
  arrange(Compound, Date, Concentrations_ID) |> 
  flextable() |> 
  bold(part = "header")
```

In @tbl-check-pheno-data-2, we check discrepancies between the number of barcode replicates reported in `Table of compounds` with the number of replicates available in barcode counts matrices. [And it turned out that `compound`: XAV-939, `Date`: 220322, is reported with 4 replicates, while only 2 could be found in [`exp220322` barcode count matrix](./data/barcode-counts/exp220322.csv)]{fg="red"}

```{r}
#| label: tbl-check-pheno-data-2
#| lst-label: lst-check-pheno-data-2
#| lst-cap: Secound round of data wrangling quality controls on *counts* versus *phenotype data*, focusing on divergent number of replicates.
#| tbl-cap: Secound round of data wrangling quality controls on *counts* versus *phenotype data*, focusing on divergent number of replicates.

replicate_inconsistencies <- pheno_data |> 
  dplyr::inner_join(ID_mapping, 
                    by = dplyr::join_by(Compound, 
                                        Date, `Run date`, 
                                        Duration_ID, Concentrations_ID)) |>
  group_by(Batch_ID, Compound, Date, Replicates, Concentrations_ID,Duration_ID) |>
  summarise(n = n()) |>
  filter(n != Replicates)

flextable(replicate_inconsistencies) |>
  autofit() |>
  bold(part = "header")

```

### Save phenotype Metadata

By applying all the formatting analyses reported in @sec-metadata-phenotypes, we generate in @tbl-phenotype-metadata-saving a global metadata phenotypic table, adhering to tidy principles [@tip-tidyformat]. 

::: {#tip-tidyformat .callout-tip title="Tidy Data Format (Key Principles)" collapse="true"}

1. **Each variable has its own column**.
2. **Each observation has its own row** – Every row corresponds to one observation.
3. **Each value has its own cell** – Each cell contains a single, unique value.

This format streamlines data wrangling, and generally speaking, data analysis and visualisation. In other words, prefer simpler `CSV` formats for the experimental design, and avoid *cell fusion* in Excel documents. Finally, for the formatted tabular representation in documentations, I use `flextable`.

:::

```{r}
#| label: tbl-phenotype-metadata-saving
#| lst-label: lst-save-pheno-metadata
#| lst-cap: Save the final metadata annotations for barcodes, using Today's date for historical versioning.

## step 4) Use international date formats ----
pheno_data_formatted <- pheno_data |> 
  dplyr::inner_join(ID_mapping,
                    by = dplyr::join_by(Compound, Date, `Run date`,
                                 Duration_ID, Concentrations_ID)) |> 
  dplyr::select(Batch_ID, Pathway, MoA,
                Compound, Samples_ID, 
                Replicates, Replicates_ID,
                Concentrations, Concentrations_ID, 
                Date, `Run date`, Duration, Duration_ID) |> 
  ## convert to ISO 1860 Date format
  mutate(Date = lubridate::dmy(Date) |> format(),
         `Run date` = lubridate::dmy(`Run date`), 
  ## artificially de-duplicate controls for exp, simplify the analytical workflow 
  Replicates_ID = dplyr::if_else(Batch_ID %in% c("exp200921_dose_response") &
                                   Compound == "Control",
                                 gsub("exp200921_", "exp200921_dose_response_", Replicates_ID),
                                 Replicates_ID))

## 2) QC: guarantee uniqueness of the replicates
pheno_data_deduplicated <- pheno_data_formatted |> 
  dplyr::distinct(Replicates_ID, .keep_all = TRUE)
all.equal(pheno_data_deduplicated, pheno_data_formatted)

## 3) save as .xlsx file discarded and preserved replicates

barcode_counts_summaries <- list("kept counts" = kept_barcode_summaries,
                                 "kept compounds" = pheno_data,
                                 "kept replicates" = pheno_data_formatted |> 
                                   select(Compound, Replicates_ID),
                                 "discarded counts" = barcode_discarded_summaries, 
                                 "discarded compounds"=pheno_data_discarded, 
                                 "discarded replicates" = replicates_discarded)

openxlsx::write.xlsx(x = barcode_counts_summaries,
                     file = paste0("./data/logs/barcode_metadata_overview_",
                                   today_date,".xlsx"),
                     overwrite = TRUE, asTable = TRUE)


## 4) save the tidy phenotype metatada table ----
readr::write_csv(pheno_data_formatted,
                 file = paste0("data/pheno_data_metadata_", today_date,".csv"))

flextable::flextable(head(pheno_data_formatted)) |> 
  autofit() |> 
  bold(part="header")
```


**Conclusion**: on a total of `{r} nrow(ID_mapping)`, `{r} nrow(pheno_data_formatted)` replicates are kept, and `{r} nrow(replicates_discarded)` replicates were removed.

